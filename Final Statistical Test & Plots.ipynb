{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "122f7551-b178-48b4-ad77-1515bf00dd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Set C Loaded] 15 architectures (single-run results).\n",
      "\n",
      "--- Complexity Analysis: All Sets (A + B + C) (N=18) ---\n",
      "\n",
      "[Correlation and Regression Summary – All Sets (A + B + C)]\n",
      "               Pearson_r  Pearson_p  Pearson_r_CI_low  Pearson_r_CI_high  \\\n",
      "Metric                                                                     \n",
      "gscm_score        0.0860     0.7607           -0.4459             0.5730   \n",
      "l2_norm           0.7935     0.0001            0.5189             0.9197   \n",
      "spectral_norm     0.9316     0.0000            0.8224             0.9746   \n",
      "\n",
      "               Spearman_rho  Spearman_p  Spearman_rho_CI_low  \\\n",
      "Metric                                                         \n",
      "gscm_score           0.0500      0.8595              -0.4744   \n",
      "l2_norm              0.1063      0.6746              -0.3794   \n",
      "spectral_norm        0.7358      0.0005               0.4097   \n",
      "\n",
      "               Spearman_rho_CI_high  R_squared  R2_sig_p  R_squared_CI_low  \\\n",
      "Metric                                                                       \n",
      "gscm_score                   0.5482     0.0074    0.7607            0.0000   \n",
      "l2_norm                      0.5461     0.6297    0.0001            0.2692   \n",
      "spectral_norm                0.8952     0.8679    0.0000            0.6764   \n",
      "\n",
      "               R_squared_CI_high   N  \n",
      "Metric                                \n",
      "gscm_score                0.3283  15  \n",
      "l2_norm                   0.8458  18  \n",
      "spectral_norm             0.9498  18  \n",
      "\n",
      "[Descriptives Exported] Set C descriptive stats saved to table_4_1_set_c_descriptive_stats.csv.\n",
      "\n",
      "--- Complexity Analysis: Set C (Core Experiment) (N=15) ---\n",
      "\n",
      "[Correlation and Regression Summary – Set C (Core Experiment)]\n",
      "               Pearson_r  Pearson_p  Pearson_r_CI_low  Pearson_r_CI_high  \\\n",
      "Metric                                                                     \n",
      "gscm_score        0.0860     0.7607           -0.4459             0.5730   \n",
      "l2_norm           0.1026     0.7160           -0.4324             0.5842   \n",
      "spectral_norm     0.7241     0.0023            0.3368             0.9019   \n",
      "sharpness         0.0230     0.9351           -0.4951             0.5290   \n",
      "\n",
      "               Spearman_rho  Spearman_p  Spearman_rho_CI_low  \\\n",
      "Metric                                                         \n",
      "gscm_score           0.0500      0.8595              -0.4744   \n",
      "l2_norm             -0.5429      0.0365              -0.8255   \n",
      "spectral_norm        0.5429      0.0365               0.0424   \n",
      "sharpness            0.6179      0.0141               0.1545   \n",
      "\n",
      "               Spearman_rho_CI_high  R_squared  R2_sig_p  R_squared_CI_low  \\\n",
      "Metric                                                                       \n",
      "gscm_score                   0.5482     0.0074    0.7607            0.0000   \n",
      "l2_norm                     -0.0424     0.0105    0.7160            0.0000   \n",
      "spectral_norm                0.8255     0.5244    0.0023            0.1134   \n",
      "sharpness                    0.8584     0.0005    0.9351            0.0000   \n",
      "\n",
      "               R_squared_CI_high   N  \n",
      "Metric                                \n",
      "gscm_score                0.3283  15  \n",
      "l2_norm                   0.3412  15  \n",
      "spectral_norm             0.8133  15  \n",
      "sharpness                 0.2799  15  \n",
      "\n",
      "--- Hypothesis-Oriented Summary for Set C (H3 & H4) ---\n",
      "H4 (Predictive Power): 'spectral_norm' achieves the highest R^2 (R^2 = 0.524, p = 0.0023).\n",
      "\n",
      "Analysis complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr, norm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Global Plotting Configuration\n",
    "# ----------------------------------------------------------------------\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. Data Loading and Aggregation\n",
    "# ----------------------------------------------------------------------\n",
    "def load_set_results(filepath: str, set_label: str) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Load results for a particular model set and add basic derived columns.\n",
    "\n",
    "    Expected columns (if present):\n",
    "      - params: number of trainable parameters\n",
    "      - train_error, test_error: classification error rates\n",
    "      - gen_gap: (optional) generalisation gap; if absent, computed as test - train\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[Warning] Could not find file: {filepath}. Skipping Set {set_label}.\")\n",
    "        return None\n",
    "\n",
    "    df[\"set\"] = set_label\n",
    "\n",
    "    if \"gen_gap\" not in df.columns and {\"train_error\", \"test_error\"} <= set(df.columns):\n",
    "        df[\"gen_gap\"] = df[\"test_error\"] - df[\"train_error\"]\n",
    "\n",
    "    if \"params\" in df.columns:\n",
    "        df[\"log_params\"] = np.log10(df[\"params\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def aggregate_set_c_data(df_c_raw: pd.DataFrame | None) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Pass-through for Set C results (single-run, per architecture).\n",
    "    \"\"\"\n",
    "    if df_c_raw is None:\n",
    "        return None\n",
    "\n",
    "    if \"id\" not in df_c_raw.columns:\n",
    "        raise KeyError(\"Set C results must contain an 'id' column for architecture grouping.\")\n",
    "\n",
    "    df_c = df_c_raw.copy()\n",
    "    df_c[\"set\"] = \"C\"\n",
    "    if \"params\" in df_c.columns:\n",
    "        df_c[\"log_params\"] = np.log10(df_c[\"params\"])\n",
    "\n",
    "    print(f\"\\n[Set C Loaded] {len(df_c)} architectures (single-run results).\")\n",
    "    return df_c\n",
    "\n",
    "\n",
    "def load_and_aggregate_all_sets() -> tuple[\n",
    "    pd.DataFrame,\n",
    "    pd.DataFrame | None,\n",
    "    pd.DataFrame | None,\n",
    "    pd.DataFrame | None,\n",
    "    pd.DataFrame | None,\n",
    "]:\n",
    "    \"\"\"\n",
    "    Load all sets (A, B, C) and prepare:\n",
    "\n",
    "      - df_all_mean: concatenated A, B, C\n",
    "      - df_a: Set A\n",
    "      - df_b: Set B\n",
    "      - df_c: Set C (single-run, per architecture)\n",
    "      - df_c_raw: Set C raw runs (identical to df_c here)\n",
    "    \"\"\"\n",
    "    df_a = load_set_results(\"dissertation_results_set_a.csv\", \"A\")\n",
    "    df_b = load_set_results(\"dissertation_results_set_b.csv\", \"B\")\n",
    "    df_c_raw = load_set_results(\"dissertation_results_set_c.csv\", \"C\")\n",
    "\n",
    "    df_c = aggregate_set_c_data(df_c_raw)\n",
    "\n",
    "    frames_mean = [d for d in (df_a, df_b, df_c) if d is not None]\n",
    "    if not frames_mean:\n",
    "        raise RuntimeError(\"No result files found for Sets A, B, or C.\")\n",
    "\n",
    "    df_all_mean = pd.concat(frames_mean, ignore_index=True)\n",
    "\n",
    "    return df_all_mean, df_a, df_b, df_c, df_c_raw\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. Statistical Analysis\n",
    "# ----------------------------------------------------------------------\n",
    "def fisher_ci_for_correlation(r: float, n: int, alpha: float = 0.05) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Compute the (1 - alpha) confidence interval for a correlation coefficient\n",
    "    (Pearson or Spearman) using Fisher's z-transform.\n",
    "    \"\"\"\n",
    "    if n <= 3 or np.isclose(r, 1.0) or np.isclose(r, -1.0):\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    z = np.arctanh(r)\n",
    "    se_z = 1.0 / np.sqrt(n - 3)\n",
    "    z_crit = norm.ppf(1 - alpha / 2.0)\n",
    "\n",
    "    z_low = z - z_crit * se_z\n",
    "    z_high = z + z_crit * se_z\n",
    "\n",
    "    r_low = np.tanh(z_low)\n",
    "    r_high = np.tanh(z_high)\n",
    "\n",
    "    return r_low, r_high\n",
    "\n",
    "\n",
    "def run_complexity_analysis(\n",
    "    df: pd.DataFrame,\n",
    "    label: str,\n",
    "    metrics: list[str],\n",
    "    output_csv: str | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform correlation and simple linear regression analyses.\n",
    "\n",
    "    Implements Methodology Section 4.5:\n",
    "      - Pearson and Spearman correlations (with p-values)\n",
    "      - 95% CI for Pearson r and Spearman rho (Fisher z)\n",
    "      - Simple linear regression: R^2 + F-test p-value\n",
    "      - 95% CI for R^2 derived from Pearson r CI (R^2 = r^2 in 1D regression),\n",
    "        with lower bound set to 0 when the r-CI crosses zero.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Complexity Analysis: {label} (N={len(df)}) ---\")\n",
    "\n",
    "    rows: list[dict] = []\n",
    "\n",
    "    for metric in metrics:\n",
    "        if metric not in df.columns:\n",
    "            print(f\"[Info] Metric '{metric}' not found in DataFrame for {label}; skipping.\")\n",
    "            continue\n",
    "\n",
    "        sub = df[[\"gen_gap\", metric]].dropna()\n",
    "        if sub.empty or len(sub) < 2:\n",
    "            print(f\"[Info] Not enough data for metric '{metric}' in {label} (N={len(sub)}); skipping.\")\n",
    "            continue\n",
    "\n",
    "        y = sub[\"gen_gap\"]\n",
    "        x = sub[metric]\n",
    "        n = len(sub)\n",
    "\n",
    "        r_pearson, p_pearson = pearsonr(x, y)\n",
    "        r_spearman, p_spearman = spearmanr(x, y)\n",
    "\n",
    "        r_ci_low, r_ci_high = fisher_ci_for_correlation(r_pearson, n)\n",
    "        rho_ci_low, rho_ci_high = fisher_ci_for_correlation(r_spearman, n)\n",
    "\n",
    "        X_reg = sm.add_constant(x)\n",
    "        model = sm.OLS(y, X_reg).fit()\n",
    "        r_squared = model.rsquared\n",
    "        f_pvalue = model.f_pvalue\n",
    "\n",
    "        if not np.isnan(r_ci_low):\n",
    "            if r_ci_low <= 0 <= r_ci_high:\n",
    "                r2_ci_low = 0.0\n",
    "                r2_ci_high = max(r_ci_low**2, r_ci_high**2)\n",
    "            else:\n",
    "                r2_ci_low = min(r_ci_low**2, r_ci_high**2)\n",
    "                r2_ci_high = max(r_ci_low**2, r_ci_high**2)\n",
    "        else:\n",
    "            r2_ci_low = np.nan\n",
    "            r2_ci_high = np.nan\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"Metric\": metric,\n",
    "                \"Pearson_r\": r_pearson,\n",
    "                \"Pearson_p\": p_pearson,\n",
    "                \"Pearson_r_CI_low\": r_ci_low,\n",
    "                \"Pearson_r_CI_high\": r_ci_high,\n",
    "                \"Spearman_rho\": r_spearman,\n",
    "                \"Spearman_p\": p_spearman,\n",
    "                \"Spearman_rho_CI_low\": rho_ci_low,\n",
    "                \"Spearman_rho_CI_high\": rho_ci_high,\n",
    "                \"R_squared\": r_squared,\n",
    "                \"R2_sig_p\": f_pvalue,\n",
    "                \"R_squared_CI_low\": r2_ci_low,\n",
    "                \"R_squared_CI_high\": r2_ci_high,\n",
    "                \"N\": n,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if not rows:\n",
    "        print(f\"[Warning] No valid metrics for analysis in {label}.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    stats_df = pd.DataFrame(rows)\n",
    "\n",
    "    print(f\"\\n[Correlation and Regression Summary – {label}]\")\n",
    "    print(stats_df.set_index(\"Metric\").round(4))\n",
    "\n",
    "    if output_csv is not None:\n",
    "        stats_df.to_csv(output_csv, index=False)\n",
    "\n",
    "    return stats_df\n",
    "\n",
    "\n",
    "def run_hypothesis_tests_set_c(df_c: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Specialised statistical validation for Set C to support H3 and H4.\n",
    "\n",
    "    Metrics considered:\n",
    "      - gscm_score (proposed metric)\n",
    "      - l2_norm\n",
    "      - spectral_norm\n",
    "      - sharpness\n",
    "    \"\"\"\n",
    "    metrics = [\"gscm_score\", \"l2_norm\", \"spectral_norm\", \"sharpness\"]\n",
    "    stats_df = run_complexity_analysis(\n",
    "        df_c,\n",
    "        label=\"Set C (Core Experiment)\",\n",
    "        metrics=metrics,\n",
    "        output_csv=\"table_5_1_complexity_metrics_summary_set_c.csv\",\n",
    "    )\n",
    "\n",
    "    if stats_df.empty:\n",
    "        return stats_df\n",
    "\n",
    "    best_r2_idx = stats_df[\"R_squared\"].idxmax()\n",
    "    best_r2_row = stats_df.loc[best_r2_idx]\n",
    "\n",
    "    print(\"\\n--- Hypothesis-Oriented Summary for Set C (H3 & H4) ---\")\n",
    "    print(\n",
    "        f\"H4 (Predictive Power): '{best_r2_row['Metric']}' achieves the highest \"\n",
    "        f\"R^2 (R^2 = {best_r2_row['R_squared']:.3f}, p = {best_r2_row['R2_sig_p']:.4f}).\"\n",
    "    )\n",
    "\n",
    "    return stats_df\n",
    "\n",
    "\n",
    "def export_set_c_descriptives(\n",
    "    df_c: pd.DataFrame,\n",
    "    output_csv: str = \"table_4_1_set_c_descriptive_stats.csv\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Export per-architecture results for Set C (single-run values).\n",
    "    \"\"\"\n",
    "    columns = [\n",
    "        \"id\",\n",
    "        \"params\",\n",
    "        \"log_params\",\n",
    "        \"train_error\",\n",
    "        \"test_error\",\n",
    "        \"gen_gap\",\n",
    "        \"gscm_score\",\n",
    "        \"l2_norm\",\n",
    "        \"spectral_norm\",\n",
    "        \"sharpness\",\n",
    "    ]\n",
    "    cols_present = [c for c in columns if c in df_c.columns]\n",
    "    df_c[cols_present].to_csv(output_csv, index=False)\n",
    "    print(f\"\\n[Descriptives Exported] Set C descriptive stats saved to {output_csv}.\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. Visualisations (Figures 5.1–5.4)\n",
    "# ----------------------------------------------------------------------\n",
    "def plot_double_descent_set_c(\n",
    "    df_c: pd.DataFrame,\n",
    "    output_path: str = \"figure_5_1_double_descent_set_c.png\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Figure 5.1: Empirical Double Descent Curve (Model Set C)\n",
    "\n",
    "    - Train and test error vs log10(params)\n",
    "    \"\"\"\n",
    "    if df_c is None or df_c.empty:\n",
    "        print(\"[Warning] Set C DataFrame is empty; skipping Figure 5.1.\")\n",
    "        return\n",
    "\n",
    "    df_sorted = df_c.sort_values(\"log_params\")\n",
    "    x = df_sorted[\"log_params\"]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    y_test = df_sorted[\"test_error\"]\n",
    "    plt.plot(x, y_test, marker=\"o\", linestyle=\"-\", label=\"Test Error\")\n",
    "\n",
    "    y_train = df_sorted[\"train_error\"]\n",
    "    plt.plot(x, y_train, marker=\"x\", linestyle=\"--\", label=\"Train Error\")\n",
    "\n",
    "    plt.title(\"Figure 5.1: Empirical Double Descent Curve (Model Set C)\")\n",
    "    plt.xlabel(\"Model Complexity (log10 of Trainable Parameters)\")\n",
    "    plt.ylabel(\"Classification Error Rate\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_complexity_vs_gen_gap_set_c(\n",
    "    df_c: pd.DataFrame,\n",
    "    output_path: str = \"figure_5_2_complexity_vs_gen_gap_set_c.png\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Figure 5.2: Complexity Metrics versus Generalisation Gap (Model Set C)\n",
    "\n",
    "    Panels:\n",
    "      - L2 Norm vs GenGap\n",
    "      - Spectral Norm vs GenGap\n",
    "      - GSCM vs GenGap\n",
    "    \"\"\"\n",
    "    if df_c is None or df_c.empty:\n",
    "        print(\"[Warning] Set C DataFrame is empty; skipping Figure 5.2.\")\n",
    "        return\n",
    "\n",
    "    metrics_to_plot = [\n",
    "        (\"l2_norm\", r\"$\\ell_2$ Norm ($N$)\"),\n",
    "        (\"spectral_norm\", \"Spectral Norm Proxy\"),\n",
    "        (\"gscm_score\", \"GSCM (Proposed Metric)\"),\n",
    "    ]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    for ax, (metric_col, display_name) in zip(axes, metrics_to_plot):\n",
    "        if metric_col not in df_c.columns or \"gen_gap\" not in df_c.columns:\n",
    "            ax.set_title(f\"{display_name}\\nPearson r = N/A (missing data)\")\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        base = df_c[[metric_col, \"gen_gap\"]].dropna()\n",
    "        if base.empty:\n",
    "            ax.set_title(f\"{display_name}\\nPearson r = N/A (no data)\")\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        x = base[metric_col]\n",
    "        y = base[\"gen_gap\"]\n",
    "        n = len(base)\n",
    "\n",
    "        if n >= 2:\n",
    "            sns.regplot(\n",
    "                x=x,\n",
    "                y=y,\n",
    "                ax=ax,\n",
    "                scatter_kws={\"s\": 40, \"alpha\": 0.7},\n",
    "                line_kws={\"linewidth\": 2},\n",
    "            )\n",
    "        else:\n",
    "            ax.scatter(x, y, s=40, alpha=0.7)\n",
    "\n",
    "        if n >= 2:\n",
    "            r_val, _ = pearsonr(x, y)\n",
    "            title_suffix = f\"Pearson r = {r_val:.3f}\"\n",
    "        else:\n",
    "            title_suffix = \"Pearson r = N/A (N < 2)\"\n",
    "\n",
    "        ax.set_title(f\"{display_name}\\n{title_suffix}\")\n",
    "        ax.set_xlabel(display_name)\n",
    "        ax.set_ylabel(\"Generalisation Gap\")\n",
    "        ax.grid(True, which=\"both\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\n",
    "        \"Figure 5.2: Complexity Metrics versus Generalisation Gap (Model Set C)\",\n",
    "        y=1.02,\n",
    "        fontsize=16,\n",
    "    )\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_gen_gap_vs_log_params_all_sets(\n",
    "    df_all: pd.DataFrame,\n",
    "    output_path: str = \"figure_5_3_gen_gap_vs_log_params_all_sets.png\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Figure 5.3: Generalisation Gap vs Model Complexity (All Sets)\n",
    "    \"\"\"\n",
    "    if df_all is None or df_all.empty:\n",
    "        print(\"[Warning] Global DataFrame is empty; skipping Figure 5.3.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=df_all, x=\"log_params\", y=\"gen_gap\", hue=\"set\", style=\"set\", s=60)\n",
    "\n",
    "    plt.title(\"Figure 5.3: Generalisation Gap vs Model Complexity (All Sets)\")\n",
    "    plt.xlabel(\"Model Complexity (log10 of Trainable Parameters)\")\n",
    "    plt.ylabel(\"Generalisation Gap\")\n",
    "    plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.6)\n",
    "    plt.legend(title=\"Model Set\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_gen_gap_vs_log_params_by_set(\n",
    "    df_a: pd.DataFrame | None,\n",
    "    df_b: pd.DataFrame | None,\n",
    "    df_c: pd.DataFrame | None,\n",
    "    output_path: str = \"figure_5_4_gen_gap_vs_log_params_by_set.png\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Figure 5.4: Generalisation Gap vs Model Complexity (Per Set)\n",
    "    \"\"\"\n",
    "    sets_data = [(\"A\", df_a), (\"B\", df_b), (\"C\", df_c)]\n",
    "    available = [(label, df) for (label, df) in sets_data if df is not None and not df.empty]\n",
    "\n",
    "    if not available:\n",
    "        print(\"[Warning] No per-set data available; skipping Figure 5.4.\")\n",
    "        return\n",
    "\n",
    "    n_sets = len(available)\n",
    "    fig, axes = plt.subplots(1, n_sets, figsize=(6 * n_sets, 5), sharey=True)\n",
    "\n",
    "    if n_sets == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, (label, df) in zip(axes, available):\n",
    "        sns.scatterplot(data=df, x=\"log_params\", y=\"gen_gap\", s=60, ax=ax)\n",
    "        ax.set_title(f\"Set {label}\")\n",
    "        ax.set_xlabel(\"log10(Trainable Parameters)\")\n",
    "        ax.set_ylabel(\"Generalisation Gap\")\n",
    "        ax.grid(True, which=\"both\", linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"Figure 5.4: Generalisation Gap vs Model Complexity (Per Set)\", y=1.03, fontsize=16)\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 4. Main orchestration\n",
    "# ----------------------------------------------------------------------\n",
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    Run the full analysis pipeline for Sets A, B, and C.\n",
    "    \"\"\"\n",
    "    df_all_mean, df_a, df_b, df_c, df_c_raw = load_and_aggregate_all_sets()\n",
    "\n",
    "    global_metrics = [\"gscm_score\", \"l2_norm\", \"spectral_norm\"]\n",
    "    run_complexity_analysis(\n",
    "        df_all_mean,\n",
    "        label=\"All Sets (A + B + C)\",\n",
    "        metrics=global_metrics,\n",
    "        output_csv=\"table_5_2_complexity_metrics_summary_all_sets.csv\",\n",
    "    )\n",
    "\n",
    "    plot_gen_gap_vs_log_params_all_sets(df_all_mean)\n",
    "    plot_gen_gap_vs_log_params_by_set(df_a, df_b, df_c)\n",
    "\n",
    "    if df_c is not None and not df_c.empty:\n",
    "        export_set_c_descriptives(df_c)\n",
    "        run_hypothesis_tests_set_c(df_c)\n",
    "        plot_double_descent_set_c(df_c)\n",
    "        plot_complexity_vs_gen_gap_set_c(df_c)\n",
    "    else:\n",
    "        print(\"[Warning] Set C results not available or empty; skipping Set C-specific analysis and plots.\")\n",
    "\n",
    "    print(\"\\nAnalysis complete.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc086f39-e0d7-4d1b-a12c-85db93bc9167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
