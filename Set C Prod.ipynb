{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f55aaee-b0bc-4287-acd3-5a00d17d0767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device for Set C: mps\n",
      "\n",
      "--- Set C: Fashion-MNIST CNN Ensemble (GSCM Core) ---\n",
      "Architectures: 15, Epochs: 100, Device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Set C models:   0%|                             | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[C_4_8_16] parameters: 6794\n",
      "[C_4_8_16] Epoch [1/100] - Train Loss: 0.8825\n",
      "[C_4_8_16] Epoch [2/100] - Train Loss: 0.4707\n",
      "[C_4_8_16] Epoch [3/100] - Train Loss: 0.3989\n",
      "[C_4_8_16] Epoch [4/100] - Train Loss: 0.3618\n",
      "[C_4_8_16] Epoch [5/100] - Train Loss: 0.3403\n",
      "[C_4_8_16] Epoch [6/100] - Train Loss: 0.3235\n",
      "[C_4_8_16] Epoch [7/100] - Train Loss: 0.3109\n",
      "[C_4_8_16] Epoch [8/100] - Train Loss: 0.3005\n",
      "[C_4_8_16] Epoch [9/100] - Train Loss: 0.2961\n",
      "[C_4_8_16] Epoch [10/100] - Train Loss: 0.2878\n",
      "[C_4_8_16] Epoch [11/100] - Train Loss: 0.2814\n",
      "[C_4_8_16] Epoch [12/100] - Train Loss: 0.2760\n",
      "[C_4_8_16] Epoch [13/100] - Train Loss: 0.2716\n",
      "[C_4_8_16] Epoch [14/100] - Train Loss: 0.2686\n",
      "[C_4_8_16] Epoch [15/100] - Train Loss: 0.2655\n",
      "[C_4_8_16] Epoch [16/100] - Train Loss: 0.2600\n",
      "[C_4_8_16] Epoch [17/100] - Train Loss: 0.2564\n",
      "[C_4_8_16] Epoch [18/100] - Train Loss: 0.2541\n",
      "[C_4_8_16] Epoch [19/100] - Train Loss: 0.2525\n",
      "[C_4_8_16] Epoch [20/100] - Train Loss: 0.2507\n",
      "[C_4_8_16] Epoch [21/100] - Train Loss: 0.2481\n",
      "[C_4_8_16] Epoch [22/100] - Train Loss: 0.2489\n",
      "[C_4_8_16] Epoch [23/100] - Train Loss: 0.2418\n",
      "[C_4_8_16] Epoch [24/100] - Train Loss: 0.2421\n",
      "[C_4_8_16] Epoch [25/100] - Train Loss: 0.2357\n",
      "[C_4_8_16] Epoch [26/100] - Train Loss: 0.2364\n",
      "[C_4_8_16] Epoch [27/100] - Train Loss: 0.2339\n",
      "[C_4_8_16] Epoch [28/100] - Train Loss: 0.2337\n",
      "[C_4_8_16] Epoch [29/100] - Train Loss: 0.2306\n",
      "[C_4_8_16] Epoch [30/100] - Train Loss: 0.2283\n",
      "[C_4_8_16] Epoch [31/100] - Train Loss: 0.2285\n",
      "[C_4_8_16] Epoch [32/100] - Train Loss: 0.2248\n",
      "[C_4_8_16] Epoch [33/100] - Train Loss: 0.2243\n",
      "[C_4_8_16] Epoch [34/100] - Train Loss: 0.2225\n",
      "[C_4_8_16] Epoch [35/100] - Train Loss: 0.2219\n",
      "[C_4_8_16] Epoch [36/100] - Train Loss: 0.2203\n",
      "[C_4_8_16] Epoch [37/100] - Train Loss: 0.2181\n",
      "[C_4_8_16] Epoch [38/100] - Train Loss: 0.2158\n",
      "[C_4_8_16] Epoch [39/100] - Train Loss: 0.2168\n",
      "[C_4_8_16] Epoch [40/100] - Train Loss: 0.2149\n",
      "[C_4_8_16] Epoch [41/100] - Train Loss: 0.2140\n",
      "[C_4_8_16] Epoch [42/100] - Train Loss: 0.2120\n",
      "[C_4_8_16] Epoch [43/100] - Train Loss: 0.2119\n",
      "[C_4_8_16] Epoch [44/100] - Train Loss: 0.2104\n",
      "[C_4_8_16] Epoch [45/100] - Train Loss: 0.2088\n",
      "[C_4_8_16] Epoch [46/100] - Train Loss: 0.2070\n",
      "[C_4_8_16] Epoch [47/100] - Train Loss: 0.2070\n",
      "[C_4_8_16] Epoch [48/100] - Train Loss: 0.2053\n",
      "[C_4_8_16] Epoch [49/100] - Train Loss: 0.2046\n",
      "[C_4_8_16] Epoch [50/100] - Train Loss: 0.2022\n",
      "[C_4_8_16] Epoch [51/100] - Train Loss: 0.2024\n",
      "[C_4_8_16] Epoch [52/100] - Train Loss: 0.2026\n",
      "[C_4_8_16] Epoch [53/100] - Train Loss: 0.2003\n",
      "[C_4_8_16] Epoch [54/100] - Train Loss: 0.1997\n",
      "[C_4_8_16] Epoch [55/100] - Train Loss: 0.1982\n",
      "[C_4_8_16] Epoch [56/100] - Train Loss: 0.1978\n",
      "[C_4_8_16] Epoch [57/100] - Train Loss: 0.1963\n",
      "[C_4_8_16] Epoch [58/100] - Train Loss: 0.1958\n",
      "[C_4_8_16] Epoch [59/100] - Train Loss: 0.1944\n",
      "[C_4_8_16] Epoch [60/100] - Train Loss: 0.1936\n",
      "[C_4_8_16] Epoch [61/100] - Train Loss: 0.1918\n",
      "[C_4_8_16] Epoch [62/100] - Train Loss: 0.1907\n",
      "[C_4_8_16] Epoch [63/100] - Train Loss: 0.1908\n",
      "[C_4_8_16] Epoch [64/100] - Train Loss: 0.1896\n",
      "[C_4_8_16] Epoch [65/100] - Train Loss: 0.1886\n",
      "[C_4_8_16] Epoch [66/100] - Train Loss: 0.1883\n",
      "[C_4_8_16] Epoch [67/100] - Train Loss: 0.1869\n",
      "[C_4_8_16] Epoch [68/100] - Train Loss: 0.1866\n",
      "[C_4_8_16] Epoch [69/100] - Train Loss: 0.1860\n",
      "[C_4_8_16] Epoch [70/100] - Train Loss: 0.1846\n",
      "[C_4_8_16] Epoch [71/100] - Train Loss: 0.1843\n",
      "[C_4_8_16] Epoch [72/100] - Train Loss: 0.1836\n",
      "[C_4_8_16] Epoch [73/100] - Train Loss: 0.1832\n",
      "[C_4_8_16] Epoch [74/100] - Train Loss: 0.1826\n",
      "[C_4_8_16] Epoch [75/100] - Train Loss: 0.1820\n",
      "[C_4_8_16] Epoch [76/100] - Train Loss: 0.1815\n",
      "[C_4_8_16] Epoch [77/100] - Train Loss: 0.1799\n",
      "[C_4_8_16] Epoch [78/100] - Train Loss: 0.1791\n",
      "[C_4_8_16] Epoch [79/100] - Train Loss: 0.1798\n",
      "[C_4_8_16] Epoch [80/100] - Train Loss: 0.1785\n",
      "[C_4_8_16] Epoch [81/100] - Train Loss: 0.1781\n",
      "[C_4_8_16] Epoch [82/100] - Train Loss: 0.1775\n",
      "[C_4_8_16] Epoch [83/100] - Train Loss: 0.1771\n",
      "[C_4_8_16] Epoch [84/100] - Train Loss: 0.1767\n",
      "[C_4_8_16] Epoch [85/100] - Train Loss: 0.1762\n",
      "[C_4_8_16] Epoch [86/100] - Train Loss: 0.1758\n",
      "[C_4_8_16] Epoch [87/100] - Train Loss: 0.1754\n",
      "[C_4_8_16] Epoch [88/100] - Train Loss: 0.1749\n",
      "[C_4_8_16] Epoch [89/100] - Train Loss: 0.1747\n",
      "[C_4_8_16] Epoch [90/100] - Train Loss: 0.1744\n",
      "[C_4_8_16] Epoch [91/100] - Train Loss: 0.1743\n",
      "[C_4_8_16] Epoch [92/100] - Train Loss: 0.1741\n",
      "[C_4_8_16] Epoch [93/100] - Train Loss: 0.1738\n",
      "[C_4_8_16] Epoch [94/100] - Train Loss: 0.1735\n",
      "[C_4_8_16] Epoch [95/100] - Train Loss: 0.1734\n",
      "[C_4_8_16] Epoch [96/100] - Train Loss: 0.1732\n",
      "[C_4_8_16] Epoch [97/100] - Train Loss: 0.1732\n",
      "[C_4_8_16] Epoch [98/100] - Train Loss: 0.1730\n",
      "[C_4_8_16] Epoch [99/100] - Train Loss: 0.1730\n",
      "[C_4_8_16] Epoch [100/100] - Train Loss: 0.1729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r7/j8qcxj351zv_wpqhpts6z__40000gn/T/ipykernel_60051/2540137522.py:64: UserWarning: The operator 'aten::linalg_svd' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:14.)\n",
      "  _, S, _ = torch.linalg.svd(W, full_matrices=False)\n",
      "Training Set C models:   7%|█▏                | 1/15 [08:40<2:01:30, 520.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[C_8_16_32] parameters: 26698\n",
      "[C_8_16_32] Epoch [1/100] - Train Loss: 0.7414\n",
      "[C_8_16_32] Epoch [2/100] - Train Loss: 0.4099\n",
      "[C_8_16_32] Epoch [3/100] - Train Loss: 0.3552\n",
      "[C_8_16_32] Epoch [4/100] - Train Loss: 0.3228\n",
      "[C_8_16_32] Epoch [5/100] - Train Loss: 0.3036\n",
      "[C_8_16_32] Epoch [6/100] - Train Loss: 0.2925\n",
      "[C_8_16_32] Epoch [7/100] - Train Loss: 0.2774\n",
      "[C_8_16_32] Epoch [8/100] - Train Loss: 0.2648\n",
      "[C_8_16_32] Epoch [9/100] - Train Loss: 0.2578\n",
      "[C_8_16_32] Epoch [10/100] - Train Loss: 0.2466\n",
      "[C_8_16_32] Epoch [11/100] - Train Loss: 0.2416\n",
      "[C_8_16_32] Epoch [12/100] - Train Loss: 0.2327\n",
      "[C_8_16_32] Epoch [13/100] - Train Loss: 0.2289\n",
      "[C_8_16_32] Epoch [14/100] - Train Loss: 0.2228\n",
      "[C_8_16_32] Epoch [15/100] - Train Loss: 0.2172\n",
      "[C_8_16_32] Epoch [16/100] - Train Loss: 0.2097\n",
      "[C_8_16_32] Epoch [17/100] - Train Loss: 0.2050\n",
      "[C_8_16_32] Epoch [18/100] - Train Loss: 0.1998\n",
      "[C_8_16_32] Epoch [19/100] - Train Loss: 0.1950\n",
      "[C_8_16_32] Epoch [20/100] - Train Loss: 0.1941\n",
      "[C_8_16_32] Epoch [21/100] - Train Loss: 0.1881\n",
      "[C_8_16_32] Epoch [22/100] - Train Loss: 0.1847\n",
      "[C_8_16_32] Epoch [23/100] - Train Loss: 0.1805\n",
      "[C_8_16_32] Epoch [24/100] - Train Loss: 0.1745\n",
      "[C_8_16_32] Epoch [25/100] - Train Loss: 0.1705\n",
      "[C_8_16_32] Epoch [26/100] - Train Loss: 0.1698\n",
      "[C_8_16_32] Epoch [27/100] - Train Loss: 0.1647\n",
      "[C_8_16_32] Epoch [28/100] - Train Loss: 0.1619\n",
      "[C_8_16_32] Epoch [29/100] - Train Loss: 0.1598\n",
      "[C_8_16_32] Epoch [30/100] - Train Loss: 0.1557\n",
      "[C_8_16_32] Epoch [31/100] - Train Loss: 0.1516\n",
      "[C_8_16_32] Epoch [32/100] - Train Loss: 0.1496\n",
      "[C_8_16_32] Epoch [33/100] - Train Loss: 0.1464\n",
      "[C_8_16_32] Epoch [34/100] - Train Loss: 0.1433\n",
      "[C_8_16_32] Epoch [35/100] - Train Loss: 0.1413\n",
      "[C_8_16_32] Epoch [36/100] - Train Loss: 0.1368\n",
      "[C_8_16_32] Epoch [37/100] - Train Loss: 0.1346\n",
      "[C_8_16_32] Epoch [38/100] - Train Loss: 0.1315\n",
      "[C_8_16_32] Epoch [39/100] - Train Loss: 0.1296\n",
      "[C_8_16_32] Epoch [40/100] - Train Loss: 0.1255\n",
      "[C_8_16_32] Epoch [41/100] - Train Loss: 0.1231\n",
      "[C_8_16_32] Epoch [42/100] - Train Loss: 0.1226\n",
      "[C_8_16_32] Epoch [43/100] - Train Loss: 0.1183\n",
      "[C_8_16_32] Epoch [44/100] - Train Loss: 0.1168\n",
      "[C_8_16_32] Epoch [45/100] - Train Loss: 0.1146\n",
      "[C_8_16_32] Epoch [46/100] - Train Loss: 0.1134\n",
      "[C_8_16_32] Epoch [47/100] - Train Loss: 0.1072\n",
      "[C_8_16_32] Epoch [48/100] - Train Loss: 0.1048\n",
      "[C_8_16_32] Epoch [49/100] - Train Loss: 0.1037\n",
      "[C_8_16_32] Epoch [50/100] - Train Loss: 0.1003\n",
      "[C_8_16_32] Epoch [51/100] - Train Loss: 0.0975\n",
      "[C_8_16_32] Epoch [52/100] - Train Loss: 0.0970\n",
      "[C_8_16_32] Epoch [53/100] - Train Loss: 0.0935\n",
      "[C_8_16_32] Epoch [54/100] - Train Loss: 0.0922\n",
      "[C_8_16_32] Epoch [55/100] - Train Loss: 0.0879\n",
      "[C_8_16_32] Epoch [56/100] - Train Loss: 0.0882\n",
      "[C_8_16_32] Epoch [57/100] - Train Loss: 0.0844\n",
      "[C_8_16_32] Epoch [58/100] - Train Loss: 0.0848\n",
      "[C_8_16_32] Epoch [59/100] - Train Loss: 0.0812\n",
      "[C_8_16_32] Epoch [60/100] - Train Loss: 0.0789\n",
      "[C_8_16_32] Epoch [61/100] - Train Loss: 0.0771\n",
      "[C_8_16_32] Epoch [62/100] - Train Loss: 0.0747\n",
      "[C_8_16_32] Epoch [63/100] - Train Loss: 0.0740\n",
      "[C_8_16_32] Epoch [64/100] - Train Loss: 0.0707\n",
      "[C_8_16_32] Epoch [65/100] - Train Loss: 0.0698\n",
      "[C_8_16_32] Epoch [66/100] - Train Loss: 0.0658\n",
      "[C_8_16_32] Epoch [67/100] - Train Loss: 0.0667\n",
      "[C_8_16_32] Epoch [68/100] - Train Loss: 0.0635\n",
      "[C_8_16_32] Epoch [69/100] - Train Loss: 0.0623\n",
      "[C_8_16_32] Epoch [70/100] - Train Loss: 0.0598\n",
      "[C_8_16_32] Epoch [71/100] - Train Loss: 0.0593\n",
      "[C_8_16_32] Epoch [72/100] - Train Loss: 0.0567\n",
      "[C_8_16_32] Epoch [73/100] - Train Loss: 0.0559\n",
      "[C_8_16_32] Epoch [74/100] - Train Loss: 0.0545\n",
      "[C_8_16_32] Epoch [75/100] - Train Loss: 0.0534\n",
      "[C_8_16_32] Epoch [76/100] - Train Loss: 0.0524\n",
      "[C_8_16_32] Epoch [77/100] - Train Loss: 0.0503\n",
      "[C_8_16_32] Epoch [78/100] - Train Loss: 0.0505\n",
      "[C_8_16_32] Epoch [79/100] - Train Loss: 0.0487\n",
      "[C_8_16_32] Epoch [80/100] - Train Loss: 0.0476\n",
      "[C_8_16_32] Epoch [81/100] - Train Loss: 0.0468\n",
      "[C_8_16_32] Epoch [82/100] - Train Loss: 0.0460\n",
      "[C_8_16_32] Epoch [83/100] - Train Loss: 0.0453\n",
      "[C_8_16_32] Epoch [84/100] - Train Loss: 0.0446\n",
      "[C_8_16_32] Epoch [85/100] - Train Loss: 0.0437\n",
      "[C_8_16_32] Epoch [86/100] - Train Loss: 0.0433\n",
      "[C_8_16_32] Epoch [87/100] - Train Loss: 0.0426\n",
      "[C_8_16_32] Epoch [88/100] - Train Loss: 0.0421\n",
      "[C_8_16_32] Epoch [89/100] - Train Loss: 0.0416\n",
      "[C_8_16_32] Epoch [90/100] - Train Loss: 0.0413\n",
      "[C_8_16_32] Epoch [91/100] - Train Loss: 0.0410\n",
      "[C_8_16_32] Epoch [92/100] - Train Loss: 0.0406\n",
      "[C_8_16_32] Epoch [93/100] - Train Loss: 0.0403\n",
      "[C_8_16_32] Epoch [94/100] - Train Loss: 0.0401\n",
      "[C_8_16_32] Epoch [95/100] - Train Loss: 0.0399\n",
      "[C_8_16_32] Epoch [96/100] - Train Loss: 0.0397\n",
      "[C_8_16_32] Epoch [97/100] - Train Loss: 0.0396\n",
      "[C_8_16_32] Epoch [98/100] - Train Loss: 0.0395\n",
      "[C_8_16_32] Epoch [99/100] - Train Loss: 0.0394\n",
      "[C_8_16_32] Epoch [100/100] - Train Loss: 0.0394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Set C models:  13%|██▍               | 2/15 [18:25<2:01:02, 558.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[C_8_16_64] parameters: 52138\n",
      "[C_8_16_64] Epoch [1/100] - Train Loss: 0.7444\n",
      "[C_8_16_64] Epoch [2/100] - Train Loss: 0.3879\n",
      "[C_8_16_64] Epoch [3/100] - Train Loss: 0.3383\n",
      "[C_8_16_64] Epoch [4/100] - Train Loss: 0.3136\n",
      "[C_8_16_64] Epoch [5/100] - Train Loss: 0.2950\n",
      "[C_8_16_64] Epoch [6/100] - Train Loss: 0.2817\n",
      "[C_8_16_64] Epoch [7/100] - Train Loss: 0.2659\n",
      "[C_8_16_64] Epoch [8/100] - Train Loss: 0.2540\n",
      "[C_8_16_64] Epoch [9/100] - Train Loss: 0.2435\n",
      "[C_8_16_64] Epoch [10/100] - Train Loss: 0.2355\n",
      "[C_8_16_64] Epoch [11/100] - Train Loss: 0.2272\n",
      "[C_8_16_64] Epoch [12/100] - Train Loss: 0.2181\n",
      "[C_8_16_64] Epoch [13/100] - Train Loss: 0.2134\n",
      "[C_8_16_64] Epoch [14/100] - Train Loss: 0.2055\n",
      "[C_8_16_64] Epoch [15/100] - Train Loss: 0.1989\n",
      "[C_8_16_64] Epoch [16/100] - Train Loss: 0.1910\n",
      "[C_8_16_64] Epoch [17/100] - Train Loss: 0.1856\n",
      "[C_8_16_64] Epoch [18/100] - Train Loss: 0.1830\n",
      "[C_8_16_64] Epoch [19/100] - Train Loss: 0.1752\n",
      "[C_8_16_64] Epoch [20/100] - Train Loss: 0.1710\n",
      "[C_8_16_64] Epoch [21/100] - Train Loss: 0.1646\n",
      "[C_8_16_64] Epoch [22/100] - Train Loss: 0.1598\n",
      "[C_8_16_64] Epoch [23/100] - Train Loss: 0.1559\n",
      "[C_8_16_64] Epoch [24/100] - Train Loss: 0.1530\n",
      "[C_8_16_64] Epoch [25/100] - Train Loss: 0.1443\n",
      "[C_8_16_64] Epoch [26/100] - Train Loss: 0.1437\n",
      "[C_8_16_64] Epoch [27/100] - Train Loss: 0.1354\n",
      "[C_8_16_64] Epoch [28/100] - Train Loss: 0.1329\n",
      "[C_8_16_64] Epoch [29/100] - Train Loss: 0.1304\n",
      "[C_8_16_64] Epoch [30/100] - Train Loss: 0.1248\n",
      "[C_8_16_64] Epoch [31/100] - Train Loss: 0.1204\n",
      "[C_8_16_64] Epoch [32/100] - Train Loss: 0.1156\n",
      "[C_8_16_64] Epoch [33/100] - Train Loss: 0.1120\n",
      "[C_8_16_64] Epoch [34/100] - Train Loss: 0.1073\n",
      "[C_8_16_64] Epoch [35/100] - Train Loss: 0.1087\n",
      "[C_8_16_64] Epoch [36/100] - Train Loss: 0.1005\n",
      "[C_8_16_64] Epoch [37/100] - Train Loss: 0.0977\n",
      "[C_8_16_64] Epoch [38/100] - Train Loss: 0.0927\n",
      "[C_8_16_64] Epoch [39/100] - Train Loss: 0.0921\n",
      "[C_8_16_64] Epoch [40/100] - Train Loss: 0.0851\n",
      "[C_8_16_64] Epoch [41/100] - Train Loss: 0.0823\n",
      "[C_8_16_64] Epoch [42/100] - Train Loss: 0.0790\n",
      "[C_8_16_64] Epoch [43/100] - Train Loss: 0.0788\n",
      "[C_8_16_64] Epoch [44/100] - Train Loss: 0.0730\n",
      "[C_8_16_64] Epoch [45/100] - Train Loss: 0.0683\n",
      "[C_8_16_64] Epoch [46/100] - Train Loss: 0.0641\n",
      "[C_8_16_64] Epoch [47/100] - Train Loss: 0.0628\n",
      "[C_8_16_64] Epoch [48/100] - Train Loss: 0.0595\n",
      "[C_8_16_64] Epoch [49/100] - Train Loss: 0.0574\n",
      "[C_8_16_64] Epoch [50/100] - Train Loss: 0.0534\n",
      "[C_8_16_64] Epoch [51/100] - Train Loss: 0.0516\n",
      "[C_8_16_64] Epoch [52/100] - Train Loss: 0.0499\n",
      "[C_8_16_64] Epoch [53/100] - Train Loss: 0.0460\n",
      "[C_8_16_64] Epoch [54/100] - Train Loss: 0.0444\n",
      "[C_8_16_64] Epoch [55/100] - Train Loss: 0.0416\n",
      "[C_8_16_64] Epoch [56/100] - Train Loss: 0.0381\n",
      "[C_8_16_64] Epoch [57/100] - Train Loss: 0.0357\n",
      "[C_8_16_64] Epoch [58/100] - Train Loss: 0.0343\n",
      "[C_8_16_64] Epoch [59/100] - Train Loss: 0.0306\n",
      "[C_8_16_64] Epoch [60/100] - Train Loss: 0.0290\n",
      "[C_8_16_64] Epoch [61/100] - Train Loss: 0.0279\n",
      "[C_8_16_64] Epoch [62/100] - Train Loss: 0.0263\n",
      "[C_8_16_64] Epoch [63/100] - Train Loss: 0.0239\n",
      "[C_8_16_64] Epoch [64/100] - Train Loss: 0.0227\n",
      "[C_8_16_64] Epoch [65/100] - Train Loss: 0.0207\n",
      "[C_8_16_64] Epoch [66/100] - Train Loss: 0.0209\n",
      "[C_8_16_64] Epoch [67/100] - Train Loss: 0.0187\n",
      "[C_8_16_64] Epoch [68/100] - Train Loss: 0.0175\n",
      "[C_8_16_64] Epoch [69/100] - Train Loss: 0.0163\n",
      "[C_8_16_64] Epoch [70/100] - Train Loss: 0.0151\n",
      "[C_8_16_64] Epoch [71/100] - Train Loss: 0.0144\n",
      "[C_8_16_64] Epoch [72/100] - Train Loss: 0.0136\n",
      "[C_8_16_64] Epoch [73/100] - Train Loss: 0.0129\n",
      "[C_8_16_64] Epoch [74/100] - Train Loss: 0.0121\n",
      "[C_8_16_64] Epoch [75/100] - Train Loss: 0.0114\n",
      "[C_8_16_64] Epoch [76/100] - Train Loss: 0.0110\n",
      "[C_8_16_64] Epoch [77/100] - Train Loss: 0.0107\n",
      "[C_8_16_64] Epoch [78/100] - Train Loss: 0.0101\n",
      "[C_8_16_64] Epoch [79/100] - Train Loss: 0.0099\n",
      "[C_8_16_64] Epoch [80/100] - Train Loss: 0.0095\n",
      "[C_8_16_64] Epoch [81/100] - Train Loss: 0.0092\n",
      "[C_8_16_64] Epoch [82/100] - Train Loss: 0.0090\n",
      "[C_8_16_64] Epoch [83/100] - Train Loss: 0.0087\n",
      "[C_8_16_64] Epoch [84/100] - Train Loss: 0.0085\n",
      "[C_8_16_64] Epoch [85/100] - Train Loss: 0.0083\n",
      "[C_8_16_64] Epoch [86/100] - Train Loss: 0.0082\n",
      "[C_8_16_64] Epoch [87/100] - Train Loss: 0.0080\n",
      "[C_8_16_64] Epoch [88/100] - Train Loss: 0.0079\n",
      "[C_8_16_64] Epoch [89/100] - Train Loss: 0.0078\n",
      "[C_8_16_64] Epoch [90/100] - Train Loss: 0.0077\n",
      "[C_8_16_64] Epoch [91/100] - Train Loss: 0.0076\n",
      "[C_8_16_64] Epoch [92/100] - Train Loss: 0.0075\n",
      "[C_8_16_64] Epoch [93/100] - Train Loss: 0.0075\n",
      "[C_8_16_64] Epoch [94/100] - Train Loss: 0.0074\n",
      "[C_8_16_64] Epoch [95/100] - Train Loss: 0.0074\n",
      "[C_8_16_64] Epoch [96/100] - Train Loss: 0.0074\n",
      "[C_8_16_64] Epoch [97/100] - Train Loss: 0.0073\n",
      "[C_8_16_64] Epoch [98/100] - Train Loss: 0.0073\n",
      "[C_8_16_64] Epoch [99/100] - Train Loss: 0.0073\n",
      "[C_8_16_64] Epoch [100/100] - Train Loss: 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Set C models:  20%|███▌              | 3/15 [28:15<1:54:33, 572.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[C_16_32_128] parameters: 206922\n",
      "[C_16_32_128] Epoch [1/100] - Train Loss: 0.6869\n",
      "[C_16_32_128] Epoch [2/100] - Train Loss: 0.3772\n",
      "[C_16_32_128] Epoch [3/100] - Train Loss: 0.3251\n",
      "[C_16_32_128] Epoch [4/100] - Train Loss: 0.2936\n",
      "[C_16_32_128] Epoch [5/100] - Train Loss: 0.2692\n",
      "[C_16_32_128] Epoch [6/100] - Train Loss: 0.2550\n",
      "[C_16_32_128] Epoch [7/100] - Train Loss: 0.2410\n",
      "[C_16_32_128] Epoch [8/100] - Train Loss: 0.2262\n",
      "[C_16_32_128] Epoch [9/100] - Train Loss: 0.2161\n",
      "[C_16_32_128] Epoch [10/100] - Train Loss: 0.2031\n",
      "[C_16_32_128] Epoch [11/100] - Train Loss: 0.1962\n",
      "[C_16_32_128] Epoch [12/100] - Train Loss: 0.1857\n",
      "[C_16_32_128] Epoch [13/100] - Train Loss: 0.1756\n",
      "[C_16_32_128] Epoch [14/100] - Train Loss: 0.1661\n",
      "[C_16_32_128] Epoch [15/100] - Train Loss: 0.1582\n",
      "[C_16_32_128] Epoch [16/100] - Train Loss: 0.1537\n",
      "[C_16_32_128] Epoch [17/100] - Train Loss: 0.1429\n",
      "[C_16_32_128] Epoch [18/100] - Train Loss: 0.1359\n",
      "[C_16_32_128] Epoch [19/100] - Train Loss: 0.1298\n",
      "[C_16_32_128] Epoch [20/100] - Train Loss: 0.1202\n",
      "[C_16_32_128] Epoch [21/100] - Train Loss: 0.1139\n",
      "[C_16_32_128] Epoch [22/100] - Train Loss: 0.1097\n",
      "[C_16_32_128] Epoch [23/100] - Train Loss: 0.1025\n",
      "[C_16_32_128] Epoch [24/100] - Train Loss: 0.0964\n",
      "[C_16_32_128] Epoch [25/100] - Train Loss: 0.0899\n",
      "[C_16_32_128] Epoch [26/100] - Train Loss: 0.0829\n",
      "[C_16_32_128] Epoch [27/100] - Train Loss: 0.0779\n",
      "[C_16_32_128] Epoch [28/100] - Train Loss: 0.0705\n",
      "[C_16_32_128] Epoch [29/100] - Train Loss: 0.0694\n",
      "[C_16_32_128] Epoch [30/100] - Train Loss: 0.0609\n",
      "[C_16_32_128] Epoch [31/100] - Train Loss: 0.0540\n",
      "[C_16_32_128] Epoch [32/100] - Train Loss: 0.0525\n",
      "[C_16_32_128] Epoch [33/100] - Train Loss: 0.0465\n",
      "[C_16_32_128] Epoch [34/100] - Train Loss: 0.0423\n",
      "[C_16_32_128] Epoch [35/100] - Train Loss: 0.0378\n",
      "[C_16_32_128] Epoch [36/100] - Train Loss: 0.0361\n",
      "[C_16_32_128] Epoch [37/100] - Train Loss: 0.0319\n",
      "[C_16_32_128] Epoch [38/100] - Train Loss: 0.0305\n",
      "[C_16_32_128] Epoch [39/100] - Train Loss: 0.0257\n",
      "[C_16_32_128] Epoch [40/100] - Train Loss: 0.0198\n",
      "[C_16_32_128] Epoch [41/100] - Train Loss: 0.0192\n",
      "[C_16_32_128] Epoch [42/100] - Train Loss: 0.0143\n",
      "[C_16_32_128] Epoch [43/100] - Train Loss: 0.0136\n",
      "[C_16_32_128] Epoch [44/100] - Train Loss: 0.0119\n",
      "[C_16_32_128] Epoch [45/100] - Train Loss: 0.0093\n",
      "[C_16_32_128] Epoch [46/100] - Train Loss: 0.0078\n",
      "[C_16_32_128] Epoch [47/100] - Train Loss: 0.0066\n",
      "[C_16_32_128] Epoch [48/100] - Train Loss: 0.0061\n",
      "[C_16_32_128] Epoch [49/100] - Train Loss: 0.0059\n",
      "[C_16_32_128] Epoch [50/100] - Train Loss: 0.0038\n",
      "[C_16_32_128] Epoch [51/100] - Train Loss: 0.0032\n",
      "[C_16_32_128] Epoch [52/100] - Train Loss: 0.0030\n",
      "[C_16_32_128] Epoch [53/100] - Train Loss: 0.0026\n",
      "[C_16_32_128] Epoch [54/100] - Train Loss: 0.0025\n",
      "[C_16_32_128] Epoch [55/100] - Train Loss: 0.0022\n",
      "[C_16_32_128] Epoch [56/100] - Train Loss: 0.0020\n",
      "[C_16_32_128] Epoch [57/100] - Train Loss: 0.0019\n",
      "[C_16_32_128] Epoch [58/100] - Train Loss: 0.0018\n",
      "[C_16_32_128] Epoch [59/100] - Train Loss: 0.0017\n",
      "[C_16_32_128] Epoch [60/100] - Train Loss: 0.0016\n",
      "[C_16_32_128] Epoch [61/100] - Train Loss: 0.0016\n",
      "[C_16_32_128] Epoch [62/100] - Train Loss: 0.0015\n",
      "[C_16_32_128] Epoch [63/100] - Train Loss: 0.0014\n",
      "[C_16_32_128] Epoch [64/100] - Train Loss: 0.0014\n",
      "[C_16_32_128] Epoch [65/100] - Train Loss: 0.0013\n",
      "[C_16_32_128] Epoch [66/100] - Train Loss: 0.0013\n",
      "[C_16_32_128] Epoch [67/100] - Train Loss: 0.0012\n",
      "[C_16_32_128] Epoch [68/100] - Train Loss: 0.0012\n",
      "[C_16_32_128] Epoch [69/100] - Train Loss: 0.0012\n",
      "[C_16_32_128] Epoch [70/100] - Train Loss: 0.0012\n",
      "[C_16_32_128] Epoch [71/100] - Train Loss: 0.0011\n",
      "[C_16_32_128] Epoch [72/100] - Train Loss: 0.0011\n",
      "[C_16_32_128] Epoch [73/100] - Train Loss: 0.0011\n",
      "[C_16_32_128] Epoch [74/100] - Train Loss: 0.0011\n",
      "[C_16_32_128] Epoch [75/100] - Train Loss: 0.0011\n",
      "[C_16_32_128] Epoch [76/100] - Train Loss: 0.0010\n",
      "[C_16_32_128] Epoch [77/100] - Train Loss: 0.0010\n",
      "[C_16_32_128] Epoch [78/100] - Train Loss: 0.0010\n",
      "[C_16_32_128] Epoch [79/100] - Train Loss: 0.0010\n",
      "[C_16_32_128] Epoch [80/100] - Train Loss: 0.0010\n",
      "[C_16_32_128] Epoch [81/100] - Train Loss: 0.0010\n",
      "[C_16_32_128] Epoch [82/100] - Train Loss: 0.0010\n",
      "[C_16_32_128] Epoch [83/100] - Train Loss: 0.0010\n",
      "[C_16_32_128] Epoch [84/100] - Train Loss: 0.0010\n",
      "[C_16_32_128] Epoch [85/100] - Train Loss: 0.0010\n",
      "[C_16_32_128] Epoch [86/100] - Train Loss: 0.0009\n",
      "[C_16_32_128] Epoch [87/100] - Train Loss: 0.0009\n",
      "[C_16_32_128] Epoch [88/100] - Train Loss: 0.0009\n",
      "[C_16_32_128] Epoch [89/100] - Train Loss: 0.0009\n",
      "[C_16_32_128] Epoch [90/100] - Train Loss: 0.0009\n",
      "[C_16_32_128] Epoch [91/100] - Train Loss: 0.0009\n",
      "[C_16_32_128] Epoch [92/100] - Train Loss: 0.0009\n",
      "[C_16_32_128] Epoch [93/100] - Train Loss: 0.0009\n",
      "[C_16_32_128] Epoch [94/100] - Train Loss: 0.0009\n",
      "[C_16_32_128] Epoch [95/100] - Train Loss: 0.0009\n",
      "[C_16_32_128] Epoch [96/100] - Train Loss: 0.0009\n",
      "[C_16_32_128] Epoch [97/100] - Train Loss: 0.0009\n",
      "[C_16_32_128] Epoch [98/100] - Train Loss: 0.0009\n",
      "[C_16_32_128] Epoch [99/100] - Train Loss: 0.0009\n",
      "[C_16_32_128] Epoch [100/100] - Train Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Set C models:  27%|████▊             | 4/15 [41:19<2:00:19, 656.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[C_16_32_256] parameters: 409034\n",
      "[C_16_32_256] Epoch [1/100] - Train Loss: 0.6475\n",
      "[C_16_32_256] Epoch [2/100] - Train Loss: 0.3644\n",
      "[C_16_32_256] Epoch [3/100] - Train Loss: 0.3167\n",
      "[C_16_32_256] Epoch [4/100] - Train Loss: 0.2872\n",
      "[C_16_32_256] Epoch [5/100] - Train Loss: 0.2643\n",
      "[C_16_32_256] Epoch [6/100] - Train Loss: 0.2464\n",
      "[C_16_32_256] Epoch [7/100] - Train Loss: 0.2326\n",
      "[C_16_32_256] Epoch [8/100] - Train Loss: 0.2196\n",
      "[C_16_32_256] Epoch [9/100] - Train Loss: 0.2076\n",
      "[C_16_32_256] Epoch [10/100] - Train Loss: 0.1969\n",
      "[C_16_32_256] Epoch [11/100] - Train Loss: 0.1860\n",
      "[C_16_32_256] Epoch [12/100] - Train Loss: 0.1757\n",
      "[C_16_32_256] Epoch [13/100] - Train Loss: 0.1675\n",
      "[C_16_32_256] Epoch [14/100] - Train Loss: 0.1580\n",
      "[C_16_32_256] Epoch [15/100] - Train Loss: 0.1513\n",
      "[C_16_32_256] Epoch [16/100] - Train Loss: 0.1416\n",
      "[C_16_32_256] Epoch [17/100] - Train Loss: 0.1342\n",
      "[C_16_32_256] Epoch [18/100] - Train Loss: 0.1242\n",
      "[C_16_32_256] Epoch [19/100] - Train Loss: 0.1175\n",
      "[C_16_32_256] Epoch [20/100] - Train Loss: 0.1063\n",
      "[C_16_32_256] Epoch [21/100] - Train Loss: 0.1017\n",
      "[C_16_32_256] Epoch [22/100] - Train Loss: 0.0925\n",
      "[C_16_32_256] Epoch [23/100] - Train Loss: 0.0877\n",
      "[C_16_32_256] Epoch [24/100] - Train Loss: 0.0799\n",
      "[C_16_32_256] Epoch [25/100] - Train Loss: 0.0731\n",
      "[C_16_32_256] Epoch [26/100] - Train Loss: 0.0675\n",
      "[C_16_32_256] Epoch [27/100] - Train Loss: 0.0621\n",
      "[C_16_32_256] Epoch [28/100] - Train Loss: 0.0532\n",
      "[C_16_32_256] Epoch [29/100] - Train Loss: 0.0507\n",
      "[C_16_32_256] Epoch [30/100] - Train Loss: 0.0447\n",
      "[C_16_32_256] Epoch [31/100] - Train Loss: 0.0405\n",
      "[C_16_32_256] Epoch [32/100] - Train Loss: 0.0350\n",
      "[C_16_32_256] Epoch [33/100] - Train Loss: 0.0329\n",
      "[C_16_32_256] Epoch [34/100] - Train Loss: 0.0291\n",
      "[C_16_32_256] Epoch [35/100] - Train Loss: 0.0249\n",
      "[C_16_32_256] Epoch [36/100] - Train Loss: 0.0229\n",
      "[C_16_32_256] Epoch [37/100] - Train Loss: 0.0183\n",
      "[C_16_32_256] Epoch [38/100] - Train Loss: 0.0174\n",
      "[C_16_32_256] Epoch [39/100] - Train Loss: 0.0131\n",
      "[C_16_32_256] Epoch [40/100] - Train Loss: 0.0092\n",
      "[C_16_32_256] Epoch [41/100] - Train Loss: 0.0081\n",
      "[C_16_32_256] Epoch [42/100] - Train Loss: 0.0068\n",
      "[C_16_32_256] Epoch [43/100] - Train Loss: 0.0066\n",
      "[C_16_32_256] Epoch [44/100] - Train Loss: 0.0041\n",
      "[C_16_32_256] Epoch [45/100] - Train Loss: 0.0038\n",
      "[C_16_32_256] Epoch [46/100] - Train Loss: 0.0028\n",
      "[C_16_32_256] Epoch [47/100] - Train Loss: 0.0024\n",
      "[C_16_32_256] Epoch [48/100] - Train Loss: 0.0022\n",
      "[C_16_32_256] Epoch [49/100] - Train Loss: 0.0020\n",
      "[C_16_32_256] Epoch [50/100] - Train Loss: 0.0017\n",
      "[C_16_32_256] Epoch [51/100] - Train Loss: 0.0016\n",
      "[C_16_32_256] Epoch [52/100] - Train Loss: 0.0015\n",
      "[C_16_32_256] Epoch [53/100] - Train Loss: 0.0014\n",
      "[C_16_32_256] Epoch [54/100] - Train Loss: 0.0013\n",
      "[C_16_32_256] Epoch [55/100] - Train Loss: 0.0012\n",
      "[C_16_32_256] Epoch [56/100] - Train Loss: 0.0012\n",
      "[C_16_32_256] Epoch [57/100] - Train Loss: 0.0011\n",
      "[C_16_32_256] Epoch [58/100] - Train Loss: 0.0011\n",
      "[C_16_32_256] Epoch [59/100] - Train Loss: 0.0010\n",
      "[C_16_32_256] Epoch [60/100] - Train Loss: 0.0010\n",
      "[C_16_32_256] Epoch [61/100] - Train Loss: 0.0010\n",
      "[C_16_32_256] Epoch [62/100] - Train Loss: 0.0009\n",
      "[C_16_32_256] Epoch [63/100] - Train Loss: 0.0009\n",
      "[C_16_32_256] Epoch [64/100] - Train Loss: 0.0009\n",
      "[C_16_32_256] Epoch [65/100] - Train Loss: 0.0009\n",
      "[C_16_32_256] Epoch [66/100] - Train Loss: 0.0008\n",
      "[C_16_32_256] Epoch [67/100] - Train Loss: 0.0008\n",
      "[C_16_32_256] Epoch [68/100] - Train Loss: 0.0008\n",
      "[C_16_32_256] Epoch [69/100] - Train Loss: 0.0008\n",
      "[C_16_32_256] Epoch [70/100] - Train Loss: 0.0008\n",
      "[C_16_32_256] Epoch [71/100] - Train Loss: 0.0008\n",
      "[C_16_32_256] Epoch [72/100] - Train Loss: 0.0007\n",
      "[C_16_32_256] Epoch [73/100] - Train Loss: 0.0007\n",
      "[C_16_32_256] Epoch [74/100] - Train Loss: 0.0007\n",
      "[C_16_32_256] Epoch [75/100] - Train Loss: 0.0007\n",
      "[C_16_32_256] Epoch [76/100] - Train Loss: 0.0007\n",
      "[C_16_32_256] Epoch [77/100] - Train Loss: 0.0007\n",
      "[C_16_32_256] Epoch [78/100] - Train Loss: 0.0007\n",
      "[C_16_32_256] Epoch [79/100] - Train Loss: 0.0007\n",
      "[C_16_32_256] Epoch [80/100] - Train Loss: 0.0007\n",
      "[C_16_32_256] Epoch [81/100] - Train Loss: 0.0007\n",
      "[C_16_32_256] Epoch [82/100] - Train Loss: 0.0007\n",
      "[C_16_32_256] Epoch [83/100] - Train Loss: 0.0007\n",
      "[C_16_32_256] Epoch [84/100] - Train Loss: 0.0007\n",
      "[C_16_32_256] Epoch [85/100] - Train Loss: 0.0007\n",
      "[C_16_32_256] Epoch [86/100] - Train Loss: 0.0007\n",
      "[C_16_32_256] Epoch [87/100] - Train Loss: 0.0007\n",
      "[C_16_32_256] Epoch [88/100] - Train Loss: 0.0006\n",
      "[C_16_32_256] Epoch [89/100] - Train Loss: 0.0006\n",
      "[C_16_32_256] Epoch [90/100] - Train Loss: 0.0006\n",
      "[C_16_32_256] Epoch [91/100] - Train Loss: 0.0006\n",
      "[C_16_32_256] Epoch [92/100] - Train Loss: 0.0006\n",
      "[C_16_32_256] Epoch [93/100] - Train Loss: 0.0006\n",
      "[C_16_32_256] Epoch [94/100] - Train Loss: 0.0006\n",
      "[C_16_32_256] Epoch [95/100] - Train Loss: 0.0006\n",
      "[C_16_32_256] Epoch [96/100] - Train Loss: 0.0006\n",
      "[C_16_32_256] Epoch [97/100] - Train Loss: 0.0006\n",
      "[C_16_32_256] Epoch [98/100] - Train Loss: 0.0006\n",
      "[C_16_32_256] Epoch [99/100] - Train Loss: 0.0006\n",
      "[C_16_32_256] Epoch [100/100] - Train Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Set C models:  33%|██████            | 5/15 [54:31<1:57:29, 704.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[C_32_64_64] parameters: 220234\n",
      "[C_32_64_64] Epoch [1/100] - Train Loss: 0.6663\n",
      "[C_32_64_64] Epoch [2/100] - Train Loss: 0.3727\n",
      "[C_32_64_64] Epoch [3/100] - Train Loss: 0.3189\n",
      "[C_32_64_64] Epoch [4/100] - Train Loss: 0.2871\n",
      "[C_32_64_64] Epoch [5/100] - Train Loss: 0.2619\n",
      "[C_32_64_64] Epoch [6/100] - Train Loss: 0.2428\n",
      "[C_32_64_64] Epoch [7/100] - Train Loss: 0.2294\n",
      "[C_32_64_64] Epoch [8/100] - Train Loss: 0.2166\n",
      "[C_32_64_64] Epoch [9/100] - Train Loss: 0.2037\n",
      "[C_32_64_64] Epoch [10/100] - Train Loss: 0.1894\n",
      "[C_32_64_64] Epoch [11/100] - Train Loss: 0.1816\n",
      "[C_32_64_64] Epoch [12/100] - Train Loss: 0.1742\n",
      "[C_32_64_64] Epoch [13/100] - Train Loss: 0.1607\n",
      "[C_32_64_64] Epoch [14/100] - Train Loss: 0.1541\n",
      "[C_32_64_64] Epoch [15/100] - Train Loss: 0.1460\n",
      "[C_32_64_64] Epoch [16/100] - Train Loss: 0.1365\n",
      "[C_32_64_64] Epoch [17/100] - Train Loss: 0.1288\n",
      "[C_32_64_64] Epoch [18/100] - Train Loss: 0.1224\n",
      "[C_32_64_64] Epoch [19/100] - Train Loss: 0.1141\n",
      "[C_32_64_64] Epoch [20/100] - Train Loss: 0.1060\n",
      "[C_32_64_64] Epoch [21/100] - Train Loss: 0.1001\n",
      "[C_32_64_64] Epoch [22/100] - Train Loss: 0.0944\n",
      "[C_32_64_64] Epoch [23/100] - Train Loss: 0.0855\n",
      "[C_32_64_64] Epoch [24/100] - Train Loss: 0.0800\n",
      "[C_32_64_64] Epoch [25/100] - Train Loss: 0.0760\n",
      "[C_32_64_64] Epoch [26/100] - Train Loss: 0.0675\n",
      "[C_32_64_64] Epoch [27/100] - Train Loss: 0.0605\n",
      "[C_32_64_64] Epoch [28/100] - Train Loss: 0.0552\n",
      "[C_32_64_64] Epoch [29/100] - Train Loss: 0.0512\n",
      "[C_32_64_64] Epoch [30/100] - Train Loss: 0.0450\n",
      "[C_32_64_64] Epoch [31/100] - Train Loss: 0.0413\n",
      "[C_32_64_64] Epoch [32/100] - Train Loss: 0.0396\n",
      "[C_32_64_64] Epoch [33/100] - Train Loss: 0.0331\n",
      "[C_32_64_64] Epoch [34/100] - Train Loss: 0.0290\n",
      "[C_32_64_64] Epoch [35/100] - Train Loss: 0.0247\n",
      "[C_32_64_64] Epoch [36/100] - Train Loss: 0.0216\n",
      "[C_32_64_64] Epoch [37/100] - Train Loss: 0.0197\n",
      "[C_32_64_64] Epoch [38/100] - Train Loss: 0.0169\n",
      "[C_32_64_64] Epoch [39/100] - Train Loss: 0.0156\n",
      "[C_32_64_64] Epoch [40/100] - Train Loss: 0.0154\n",
      "[C_32_64_64] Epoch [41/100] - Train Loss: 0.0101\n",
      "[C_32_64_64] Epoch [42/100] - Train Loss: 0.0092\n",
      "[C_32_64_64] Epoch [43/100] - Train Loss: 0.0073\n",
      "[C_32_64_64] Epoch [44/100] - Train Loss: 0.0054\n",
      "[C_32_64_64] Epoch [45/100] - Train Loss: 0.0044\n",
      "[C_32_64_64] Epoch [46/100] - Train Loss: 0.0036\n",
      "[C_32_64_64] Epoch [47/100] - Train Loss: 0.0031\n",
      "[C_32_64_64] Epoch [48/100] - Train Loss: 0.0028\n",
      "[C_32_64_64] Epoch [49/100] - Train Loss: 0.0024\n",
      "[C_32_64_64] Epoch [50/100] - Train Loss: 0.0022\n",
      "[C_32_64_64] Epoch [51/100] - Train Loss: 0.0021\n",
      "[C_32_64_64] Epoch [52/100] - Train Loss: 0.0019\n",
      "[C_32_64_64] Epoch [53/100] - Train Loss: 0.0018\n",
      "[C_32_64_64] Epoch [54/100] - Train Loss: 0.0017\n",
      "[C_32_64_64] Epoch [55/100] - Train Loss: 0.0016\n",
      "[C_32_64_64] Epoch [56/100] - Train Loss: 0.0015\n",
      "[C_32_64_64] Epoch [57/100] - Train Loss: 0.0015\n",
      "[C_32_64_64] Epoch [58/100] - Train Loss: 0.0014\n",
      "[C_32_64_64] Epoch [59/100] - Train Loss: 0.0014\n",
      "[C_32_64_64] Epoch [60/100] - Train Loss: 0.0013\n",
      "[C_32_64_64] Epoch [61/100] - Train Loss: 0.0013\n",
      "[C_32_64_64] Epoch [62/100] - Train Loss: 0.0012\n",
      "[C_32_64_64] Epoch [63/100] - Train Loss: 0.0012\n",
      "[C_32_64_64] Epoch [64/100] - Train Loss: 0.0012\n",
      "[C_32_64_64] Epoch [65/100] - Train Loss: 0.0011\n",
      "[C_32_64_64] Epoch [66/100] - Train Loss: 0.0011\n",
      "[C_32_64_64] Epoch [67/100] - Train Loss: 0.0011\n",
      "[C_32_64_64] Epoch [68/100] - Train Loss: 0.0010\n",
      "[C_32_64_64] Epoch [69/100] - Train Loss: 0.0010\n",
      "[C_32_64_64] Epoch [70/100] - Train Loss: 0.0010\n",
      "[C_32_64_64] Epoch [71/100] - Train Loss: 0.0010\n",
      "[C_32_64_64] Epoch [72/100] - Train Loss: 0.0010\n",
      "[C_32_64_64] Epoch [73/100] - Train Loss: 0.0010\n",
      "[C_32_64_64] Epoch [74/100] - Train Loss: 0.0010\n",
      "[C_32_64_64] Epoch [75/100] - Train Loss: 0.0009\n",
      "[C_32_64_64] Epoch [76/100] - Train Loss: 0.0009\n",
      "[C_32_64_64] Epoch [77/100] - Train Loss: 0.0009\n",
      "[C_32_64_64] Epoch [78/100] - Train Loss: 0.0009\n",
      "[C_32_64_64] Epoch [79/100] - Train Loss: 0.0009\n",
      "[C_32_64_64] Epoch [80/100] - Train Loss: 0.0009\n",
      "[C_32_64_64] Epoch [81/100] - Train Loss: 0.0009\n",
      "[C_32_64_64] Epoch [82/100] - Train Loss: 0.0009\n",
      "[C_32_64_64] Epoch [83/100] - Train Loss: 0.0009\n",
      "[C_32_64_64] Epoch [84/100] - Train Loss: 0.0009\n",
      "[C_32_64_64] Epoch [85/100] - Train Loss: 0.0009\n",
      "[C_32_64_64] Epoch [86/100] - Train Loss: 0.0009\n",
      "[C_32_64_64] Epoch [87/100] - Train Loss: 0.0009\n",
      "[C_32_64_64] Epoch [88/100] - Train Loss: 0.0009\n",
      "[C_32_64_64] Epoch [89/100] - Train Loss: 0.0008\n",
      "[C_32_64_64] Epoch [90/100] - Train Loss: 0.0008\n",
      "[C_32_64_64] Epoch [91/100] - Train Loss: 0.0008\n",
      "[C_32_64_64] Epoch [92/100] - Train Loss: 0.0008\n",
      "[C_32_64_64] Epoch [93/100] - Train Loss: 0.0008\n",
      "[C_32_64_64] Epoch [94/100] - Train Loss: 0.0008\n",
      "[C_32_64_64] Epoch [95/100] - Train Loss: 0.0008\n",
      "[C_32_64_64] Epoch [96/100] - Train Loss: 0.0008\n",
      "[C_32_64_64] Epoch [97/100] - Train Loss: 0.0008\n",
      "[C_32_64_64] Epoch [98/100] - Train Loss: 0.0008\n",
      "[C_32_64_64] Epoch [99/100] - Train Loss: 0.0008\n",
      "[C_32_64_64] Epoch [100/100] - Train Loss: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Set C models:  40%|██████▍         | 6/15 [1:09:00<1:54:07, 760.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[C_32_64_128] parameters: 421642\n",
      "[C_32_64_128] Epoch [1/100] - Train Loss: 0.6558\n",
      "[C_32_64_128] Epoch [2/100] - Train Loss: 0.3662\n",
      "[C_32_64_128] Epoch [3/100] - Train Loss: 0.3131\n",
      "[C_32_64_128] Epoch [4/100] - Train Loss: 0.2786\n",
      "[C_32_64_128] Epoch [5/100] - Train Loss: 0.2578\n",
      "[C_32_64_128] Epoch [6/100] - Train Loss: 0.2377\n",
      "[C_32_64_128] Epoch [7/100] - Train Loss: 0.2258\n",
      "[C_32_64_128] Epoch [8/100] - Train Loss: 0.2109\n",
      "[C_32_64_128] Epoch [9/100] - Train Loss: 0.1995\n",
      "[C_32_64_128] Epoch [10/100] - Train Loss: 0.1868\n",
      "[C_32_64_128] Epoch [11/100] - Train Loss: 0.1765\n",
      "[C_32_64_128] Epoch [12/100] - Train Loss: 0.1648\n",
      "[C_32_64_128] Epoch [13/100] - Train Loss: 0.1568\n",
      "[C_32_64_128] Epoch [14/100] - Train Loss: 0.1468\n",
      "[C_32_64_128] Epoch [15/100] - Train Loss: 0.1369\n",
      "[C_32_64_128] Epoch [16/100] - Train Loss: 0.1327\n",
      "[C_32_64_128] Epoch [17/100] - Train Loss: 0.1205\n",
      "[C_32_64_128] Epoch [18/100] - Train Loss: 0.1159\n",
      "[C_32_64_128] Epoch [19/100] - Train Loss: 0.1044\n",
      "[C_32_64_128] Epoch [20/100] - Train Loss: 0.0959\n",
      "[C_32_64_128] Epoch [21/100] - Train Loss: 0.0901\n",
      "[C_32_64_128] Epoch [22/100] - Train Loss: 0.0803\n",
      "[C_32_64_128] Epoch [23/100] - Train Loss: 0.0749\n",
      "[C_32_64_128] Epoch [24/100] - Train Loss: 0.0677\n",
      "[C_32_64_128] Epoch [25/100] - Train Loss: 0.0647\n",
      "[C_32_64_128] Epoch [26/100] - Train Loss: 0.0576\n",
      "[C_32_64_128] Epoch [27/100] - Train Loss: 0.0529\n",
      "[C_32_64_128] Epoch [28/100] - Train Loss: 0.0482\n",
      "[C_32_64_128] Epoch [29/100] - Train Loss: 0.0422\n",
      "[C_32_64_128] Epoch [30/100] - Train Loss: 0.0372\n",
      "[C_32_64_128] Epoch [31/100] - Train Loss: 0.0367\n",
      "[C_32_64_128] Epoch [32/100] - Train Loss: 0.0278\n",
      "[C_32_64_128] Epoch [33/100] - Train Loss: 0.0241\n",
      "[C_32_64_128] Epoch [34/100] - Train Loss: 0.0203\n",
      "[C_32_64_128] Epoch [35/100] - Train Loss: 0.0184\n",
      "[C_32_64_128] Epoch [36/100] - Train Loss: 0.0149\n",
      "[C_32_64_128] Epoch [37/100] - Train Loss: 0.0120\n",
      "[C_32_64_128] Epoch [38/100] - Train Loss: 0.0110\n",
      "[C_32_64_128] Epoch [39/100] - Train Loss: 0.0066\n",
      "[C_32_64_128] Epoch [40/100] - Train Loss: 0.0060\n",
      "[C_32_64_128] Epoch [41/100] - Train Loss: 0.0061\n",
      "[C_32_64_128] Epoch [42/100] - Train Loss: 0.0048\n",
      "[C_32_64_128] Epoch [43/100] - Train Loss: 0.0034\n",
      "[C_32_64_128] Epoch [44/100] - Train Loss: 0.0029\n",
      "[C_32_64_128] Epoch [45/100] - Train Loss: 0.0026\n",
      "[C_32_64_128] Epoch [46/100] - Train Loss: 0.0023\n",
      "[C_32_64_128] Epoch [47/100] - Train Loss: 0.0021\n",
      "[C_32_64_128] Epoch [48/100] - Train Loss: 0.0018\n",
      "[C_32_64_128] Epoch [49/100] - Train Loss: 0.0018\n",
      "[C_32_64_128] Epoch [50/100] - Train Loss: 0.0016\n",
      "[C_32_64_128] Epoch [51/100] - Train Loss: 0.0015\n",
      "[C_32_64_128] Epoch [52/100] - Train Loss: 0.0014\n",
      "[C_32_64_128] Epoch [53/100] - Train Loss: 0.0013\n",
      "[C_32_64_128] Epoch [54/100] - Train Loss: 0.0013\n",
      "[C_32_64_128] Epoch [55/100] - Train Loss: 0.0012\n",
      "[C_32_64_128] Epoch [56/100] - Train Loss: 0.0011\n",
      "[C_32_64_128] Epoch [57/100] - Train Loss: 0.0011\n",
      "[C_32_64_128] Epoch [58/100] - Train Loss: 0.0011\n",
      "[C_32_64_128] Epoch [59/100] - Train Loss: 0.0010\n",
      "[C_32_64_128] Epoch [60/100] - Train Loss: 0.0010\n",
      "[C_32_64_128] Epoch [61/100] - Train Loss: 0.0010\n",
      "[C_32_64_128] Epoch [62/100] - Train Loss: 0.0009\n",
      "[C_32_64_128] Epoch [63/100] - Train Loss: 0.0009\n",
      "[C_32_64_128] Epoch [64/100] - Train Loss: 0.0009\n",
      "[C_32_64_128] Epoch [65/100] - Train Loss: 0.0009\n",
      "[C_32_64_128] Epoch [66/100] - Train Loss: 0.0008\n",
      "[C_32_64_128] Epoch [67/100] - Train Loss: 0.0008\n",
      "[C_32_64_128] Epoch [68/100] - Train Loss: 0.0008\n",
      "[C_32_64_128] Epoch [69/100] - Train Loss: 0.0008\n",
      "[C_32_64_128] Epoch [70/100] - Train Loss: 0.0008\n",
      "[C_32_64_128] Epoch [71/100] - Train Loss: 0.0008\n",
      "[C_32_64_128] Epoch [72/100] - Train Loss: 0.0008\n",
      "[C_32_64_128] Epoch [73/100] - Train Loss: 0.0008\n",
      "[C_32_64_128] Epoch [74/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [75/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [76/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [77/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [78/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [79/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [80/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [81/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [82/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [83/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [84/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [85/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [86/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [87/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [88/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [89/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [90/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [91/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [92/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [93/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [94/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [95/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [96/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [97/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [98/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [99/100] - Train Loss: 0.0007\n",
      "[C_32_64_128] Epoch [100/100] - Train Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Set C models:  47%|███████▍        | 7/15 [1:23:38<1:46:33, 799.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[C_32_64_256] parameters: 824458\n",
      "[C_32_64_256] Epoch [1/100] - Train Loss: 0.6688\n",
      "[C_32_64_256] Epoch [2/100] - Train Loss: 0.3626\n",
      "[C_32_64_256] Epoch [3/100] - Train Loss: 0.3109\n",
      "[C_32_64_256] Epoch [4/100] - Train Loss: 0.2795\n",
      "[C_32_64_256] Epoch [5/100] - Train Loss: 0.2575\n",
      "[C_32_64_256] Epoch [6/100] - Train Loss: 0.2421\n",
      "[C_32_64_256] Epoch [7/100] - Train Loss: 0.2207\n",
      "[C_32_64_256] Epoch [8/100] - Train Loss: 0.2077\n",
      "[C_32_64_256] Epoch [9/100] - Train Loss: 0.1975\n",
      "[C_32_64_256] Epoch [10/100] - Train Loss: 0.1849\n",
      "[C_32_64_256] Epoch [11/100] - Train Loss: 0.1765\n",
      "[C_32_64_256] Epoch [12/100] - Train Loss: 0.1667\n",
      "[C_32_64_256] Epoch [13/100] - Train Loss: 0.1532\n",
      "[C_32_64_256] Epoch [14/100] - Train Loss: 0.1440\n",
      "[C_32_64_256] Epoch [15/100] - Train Loss: 0.1344\n",
      "[C_32_64_256] Epoch [16/100] - Train Loss: 0.1267\n",
      "[C_32_64_256] Epoch [17/100] - Train Loss: 0.1194\n",
      "[C_32_64_256] Epoch [18/100] - Train Loss: 0.1086\n",
      "[C_32_64_256] Epoch [19/100] - Train Loss: 0.1021\n",
      "[C_32_64_256] Epoch [20/100] - Train Loss: 0.0929\n",
      "[C_32_64_256] Epoch [21/100] - Train Loss: 0.0883\n",
      "[C_32_64_256] Epoch [22/100] - Train Loss: 0.0793\n",
      "[C_32_64_256] Epoch [23/100] - Train Loss: 0.0700\n",
      "[C_32_64_256] Epoch [24/100] - Train Loss: 0.0625\n",
      "[C_32_64_256] Epoch [25/100] - Train Loss: 0.0599\n",
      "[C_32_64_256] Epoch [26/100] - Train Loss: 0.0537\n",
      "[C_32_64_256] Epoch [27/100] - Train Loss: 0.0463\n",
      "[C_32_64_256] Epoch [28/100] - Train Loss: 0.0405\n",
      "[C_32_64_256] Epoch [29/100] - Train Loss: 0.0388\n",
      "[C_32_64_256] Epoch [30/100] - Train Loss: 0.0351\n",
      "[C_32_64_256] Epoch [31/100] - Train Loss: 0.0288\n",
      "[C_32_64_256] Epoch [32/100] - Train Loss: 0.0242\n",
      "[C_32_64_256] Epoch [33/100] - Train Loss: 0.0226\n",
      "[C_32_64_256] Epoch [34/100] - Train Loss: 0.0168\n",
      "[C_32_64_256] Epoch [35/100] - Train Loss: 0.0173\n",
      "[C_32_64_256] Epoch [36/100] - Train Loss: 0.0135\n",
      "[C_32_64_256] Epoch [37/100] - Train Loss: 0.0097\n",
      "[C_32_64_256] Epoch [38/100] - Train Loss: 0.0087\n",
      "[C_32_64_256] Epoch [39/100] - Train Loss: 0.0067\n",
      "[C_32_64_256] Epoch [40/100] - Train Loss: 0.0058\n",
      "[C_32_64_256] Epoch [41/100] - Train Loss: 0.0047\n",
      "[C_32_64_256] Epoch [42/100] - Train Loss: 0.0033\n",
      "[C_32_64_256] Epoch [43/100] - Train Loss: 0.0028\n",
      "[C_32_64_256] Epoch [44/100] - Train Loss: 0.0024\n",
      "[C_32_64_256] Epoch [45/100] - Train Loss: 0.0021\n",
      "[C_32_64_256] Epoch [46/100] - Train Loss: 0.0018\n",
      "[C_32_64_256] Epoch [47/100] - Train Loss: 0.0016\n",
      "[C_32_64_256] Epoch [48/100] - Train Loss: 0.0015\n",
      "[C_32_64_256] Epoch [49/100] - Train Loss: 0.0014\n",
      "[C_32_64_256] Epoch [50/100] - Train Loss: 0.0013\n",
      "[C_32_64_256] Epoch [51/100] - Train Loss: 0.0012\n",
      "[C_32_64_256] Epoch [52/100] - Train Loss: 0.0012\n",
      "[C_32_64_256] Epoch [53/100] - Train Loss: 0.0011\n",
      "[C_32_64_256] Epoch [54/100] - Train Loss: 0.0011\n",
      "[C_32_64_256] Epoch [55/100] - Train Loss: 0.0010\n",
      "[C_32_64_256] Epoch [56/100] - Train Loss: 0.0010\n",
      "[C_32_64_256] Epoch [57/100] - Train Loss: 0.0009\n",
      "[C_32_64_256] Epoch [58/100] - Train Loss: 0.0009\n",
      "[C_32_64_256] Epoch [59/100] - Train Loss: 0.0009\n",
      "[C_32_64_256] Epoch [60/100] - Train Loss: 0.0009\n",
      "[C_32_64_256] Epoch [61/100] - Train Loss: 0.0008\n",
      "[C_32_64_256] Epoch [62/100] - Train Loss: 0.0008\n",
      "[C_32_64_256] Epoch [63/100] - Train Loss: 0.0008\n",
      "[C_32_64_256] Epoch [64/100] - Train Loss: 0.0008\n",
      "[C_32_64_256] Epoch [65/100] - Train Loss: 0.0008\n",
      "[C_32_64_256] Epoch [66/100] - Train Loss: 0.0007\n",
      "[C_32_64_256] Epoch [67/100] - Train Loss: 0.0007\n",
      "[C_32_64_256] Epoch [68/100] - Train Loss: 0.0007\n",
      "[C_32_64_256] Epoch [69/100] - Train Loss: 0.0007\n",
      "[C_32_64_256] Epoch [70/100] - Train Loss: 0.0007\n",
      "[C_32_64_256] Epoch [71/100] - Train Loss: 0.0007\n",
      "[C_32_64_256] Epoch [72/100] - Train Loss: 0.0007\n",
      "[C_32_64_256] Epoch [73/100] - Train Loss: 0.0007\n",
      "[C_32_64_256] Epoch [74/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [75/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [76/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [77/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [78/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [79/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [80/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [81/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [82/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [83/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [84/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [85/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [86/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [87/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [88/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [89/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [90/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [91/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [92/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [93/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [94/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [95/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [96/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [97/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [98/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [99/100] - Train Loss: 0.0006\n",
      "[C_32_64_256] Epoch [100/100] - Train Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Set C models:  53%|████████▌       | 8/15 [1:38:14<1:36:06, 823.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[C_64_128_128] parameters: 878730\n",
      "[C_64_128_128] Epoch [1/100] - Train Loss: 0.5985\n",
      "[C_64_128_128] Epoch [2/100] - Train Loss: 0.3484\n",
      "[C_64_128_128] Epoch [3/100] - Train Loss: 0.3005\n",
      "[C_64_128_128] Epoch [4/100] - Train Loss: 0.2697\n",
      "[C_64_128_128] Epoch [5/100] - Train Loss: 0.2476\n",
      "[C_64_128_128] Epoch [6/100] - Train Loss: 0.2288\n",
      "[C_64_128_128] Epoch [7/100] - Train Loss: 0.2109\n",
      "[C_64_128_128] Epoch [8/100] - Train Loss: 0.1975\n",
      "[C_64_128_128] Epoch [9/100] - Train Loss: 0.1861\n",
      "[C_64_128_128] Epoch [10/100] - Train Loss: 0.1742\n",
      "[C_64_128_128] Epoch [11/100] - Train Loss: 0.1645\n",
      "[C_64_128_128] Epoch [12/100] - Train Loss: 0.1506\n",
      "[C_64_128_128] Epoch [13/100] - Train Loss: 0.1405\n",
      "[C_64_128_128] Epoch [14/100] - Train Loss: 0.1297\n",
      "[C_64_128_128] Epoch [15/100] - Train Loss: 0.1205\n",
      "[C_64_128_128] Epoch [16/100] - Train Loss: 0.1114\n",
      "[C_64_128_128] Epoch [17/100] - Train Loss: 0.1014\n",
      "[C_64_128_128] Epoch [18/100] - Train Loss: 0.0932\n",
      "[C_64_128_128] Epoch [19/100] - Train Loss: 0.0860\n",
      "[C_64_128_128] Epoch [20/100] - Train Loss: 0.0766\n",
      "[C_64_128_128] Epoch [21/100] - Train Loss: 0.0703\n",
      "[C_64_128_128] Epoch [22/100] - Train Loss: 0.0644\n",
      "[C_64_128_128] Epoch [23/100] - Train Loss: 0.0564\n",
      "[C_64_128_128] Epoch [24/100] - Train Loss: 0.0492\n",
      "[C_64_128_128] Epoch [25/100] - Train Loss: 0.0455\n",
      "[C_64_128_128] Epoch [26/100] - Train Loss: 0.0402\n",
      "[C_64_128_128] Epoch [27/100] - Train Loss: 0.0335\n",
      "[C_64_128_128] Epoch [28/100] - Train Loss: 0.0273\n",
      "[C_64_128_128] Epoch [29/100] - Train Loss: 0.0232\n",
      "[C_64_128_128] Epoch [30/100] - Train Loss: 0.0218\n",
      "[C_64_128_128] Epoch [31/100] - Train Loss: 0.0185\n",
      "[C_64_128_128] Epoch [32/100] - Train Loss: 0.0158\n",
      "[C_64_128_128] Epoch [33/100] - Train Loss: 0.0123\n",
      "[C_64_128_128] Epoch [34/100] - Train Loss: 0.0094\n",
      "[C_64_128_128] Epoch [35/100] - Train Loss: 0.0080\n",
      "[C_64_128_128] Epoch [36/100] - Train Loss: 0.0060\n",
      "[C_64_128_128] Epoch [37/100] - Train Loss: 0.0043\n",
      "[C_64_128_128] Epoch [38/100] - Train Loss: 0.0036\n",
      "[C_64_128_128] Epoch [39/100] - Train Loss: 0.0028\n",
      "[C_64_128_128] Epoch [40/100] - Train Loss: 0.0023\n",
      "[C_64_128_128] Epoch [41/100] - Train Loss: 0.0021\n",
      "[C_64_128_128] Epoch [42/100] - Train Loss: 0.0018\n",
      "[C_64_128_128] Epoch [43/100] - Train Loss: 0.0017\n",
      "[C_64_128_128] Epoch [44/100] - Train Loss: 0.0015\n",
      "[C_64_128_128] Epoch [45/100] - Train Loss: 0.0015\n",
      "[C_64_128_128] Epoch [46/100] - Train Loss: 0.0013\n",
      "[C_64_128_128] Epoch [47/100] - Train Loss: 0.0013\n",
      "[C_64_128_128] Epoch [48/100] - Train Loss: 0.0012\n",
      "[C_64_128_128] Epoch [49/100] - Train Loss: 0.0011\n",
      "[C_64_128_128] Epoch [50/100] - Train Loss: 0.0010\n",
      "[C_64_128_128] Epoch [51/100] - Train Loss: 0.0010\n",
      "[C_64_128_128] Epoch [52/100] - Train Loss: 0.0010\n",
      "[C_64_128_128] Epoch [53/100] - Train Loss: 0.0009\n",
      "[C_64_128_128] Epoch [54/100] - Train Loss: 0.0009\n",
      "[C_64_128_128] Epoch [55/100] - Train Loss: 0.0009\n",
      "[C_64_128_128] Epoch [56/100] - Train Loss: 0.0008\n",
      "[C_64_128_128] Epoch [57/100] - Train Loss: 0.0008\n",
      "[C_64_128_128] Epoch [58/100] - Train Loss: 0.0008\n",
      "[C_64_128_128] Epoch [59/100] - Train Loss: 0.0008\n",
      "[C_64_128_128] Epoch [60/100] - Train Loss: 0.0007\n",
      "[C_64_128_128] Epoch [61/100] - Train Loss: 0.0007\n",
      "[C_64_128_128] Epoch [62/100] - Train Loss: 0.0007\n",
      "[C_64_128_128] Epoch [63/100] - Train Loss: 0.0007\n",
      "[C_64_128_128] Epoch [64/100] - Train Loss: 0.0007\n",
      "[C_64_128_128] Epoch [65/100] - Train Loss: 0.0007\n",
      "[C_64_128_128] Epoch [66/100] - Train Loss: 0.0007\n",
      "[C_64_128_128] Epoch [67/100] - Train Loss: 0.0006\n",
      "[C_64_128_128] Epoch [68/100] - Train Loss: 0.0006\n",
      "[C_64_128_128] Epoch [69/100] - Train Loss: 0.0006\n",
      "[C_64_128_128] Epoch [70/100] - Train Loss: 0.0006\n",
      "[C_64_128_128] Epoch [71/100] - Train Loss: 0.0006\n",
      "[C_64_128_128] Epoch [72/100] - Train Loss: 0.0006\n",
      "[C_64_128_128] Epoch [73/100] - Train Loss: 0.0006\n",
      "[C_64_128_128] Epoch [74/100] - Train Loss: 0.0006\n",
      "[C_64_128_128] Epoch [75/100] - Train Loss: 0.0006\n",
      "[C_64_128_128] Epoch [76/100] - Train Loss: 0.0006\n",
      "[C_64_128_128] Epoch [77/100] - Train Loss: 0.0006\n",
      "[C_64_128_128] Epoch [78/100] - Train Loss: 0.0006\n",
      "[C_64_128_128] Epoch [79/100] - Train Loss: 0.0006\n",
      "[C_64_128_128] Epoch [80/100] - Train Loss: 0.0006\n",
      "[C_64_128_128] Epoch [81/100] - Train Loss: 0.0006\n",
      "[C_64_128_128] Epoch [82/100] - Train Loss: 0.0006\n",
      "[C_64_128_128] Epoch [83/100] - Train Loss: 0.0006\n",
      "[C_64_128_128] Epoch [84/100] - Train Loss: 0.0006\n",
      "[C_64_128_128] Epoch [85/100] - Train Loss: 0.0005\n",
      "[C_64_128_128] Epoch [86/100] - Train Loss: 0.0005\n",
      "[C_64_128_128] Epoch [87/100] - Train Loss: 0.0005\n",
      "[C_64_128_128] Epoch [88/100] - Train Loss: 0.0005\n",
      "[C_64_128_128] Epoch [89/100] - Train Loss: 0.0005\n",
      "[C_64_128_128] Epoch [90/100] - Train Loss: 0.0005\n",
      "[C_64_128_128] Epoch [91/100] - Train Loss: 0.0005\n",
      "[C_64_128_128] Epoch [92/100] - Train Loss: 0.0005\n",
      "[C_64_128_128] Epoch [93/100] - Train Loss: 0.0005\n",
      "[C_64_128_128] Epoch [94/100] - Train Loss: 0.0005\n",
      "[C_64_128_128] Epoch [95/100] - Train Loss: 0.0005\n",
      "[C_64_128_128] Epoch [96/100] - Train Loss: 0.0005\n",
      "[C_64_128_128] Epoch [97/100] - Train Loss: 0.0005\n",
      "[C_64_128_128] Epoch [98/100] - Train Loss: 0.0005\n",
      "[C_64_128_128] Epoch [99/100] - Train Loss: 0.0005\n",
      "[C_64_128_128] Epoch [100/100] - Train Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Set C models:  60%|█████████      | 9/15 [2:04:41<1:46:13, 1062.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[C_64_128_256] parameters: 1682954\n",
      "[C_64_128_256] Epoch [1/100] - Train Loss: 0.5887\n",
      "[C_64_128_256] Epoch [2/100] - Train Loss: 0.3523\n",
      "[C_64_128_256] Epoch [3/100] - Train Loss: 0.2995\n",
      "[C_64_128_256] Epoch [4/100] - Train Loss: 0.2692\n",
      "[C_64_128_256] Epoch [5/100] - Train Loss: 0.2453\n",
      "[C_64_128_256] Epoch [6/100] - Train Loss: 0.2271\n",
      "[C_64_128_256] Epoch [7/100] - Train Loss: 0.2108\n",
      "[C_64_128_256] Epoch [8/100] - Train Loss: 0.1974\n",
      "[C_64_128_256] Epoch [9/100] - Train Loss: 0.1817\n",
      "[C_64_128_256] Epoch [10/100] - Train Loss: 0.1704\n",
      "[C_64_128_256] Epoch [11/100] - Train Loss: 0.1590\n",
      "[C_64_128_256] Epoch [12/100] - Train Loss: 0.1493\n",
      "[C_64_128_256] Epoch [13/100] - Train Loss: 0.1377\n",
      "[C_64_128_256] Epoch [14/100] - Train Loss: 0.1280\n",
      "[C_64_128_256] Epoch [15/100] - Train Loss: 0.1217\n",
      "[C_64_128_256] Epoch [16/100] - Train Loss: 0.1110\n",
      "[C_64_128_256] Epoch [17/100] - Train Loss: 0.0993\n",
      "[C_64_128_256] Epoch [18/100] - Train Loss: 0.0902\n",
      "[C_64_128_256] Epoch [19/100] - Train Loss: 0.0815\n",
      "[C_64_128_256] Epoch [20/100] - Train Loss: 0.0727\n",
      "[C_64_128_256] Epoch [21/100] - Train Loss: 0.0649\n",
      "[C_64_128_256] Epoch [22/100] - Train Loss: 0.0593\n",
      "[C_64_128_256] Epoch [23/100] - Train Loss: 0.0500\n",
      "[C_64_128_256] Epoch [24/100] - Train Loss: 0.0489\n",
      "[C_64_128_256] Epoch [25/100] - Train Loss: 0.0420\n",
      "[C_64_128_256] Epoch [26/100] - Train Loss: 0.0382\n",
      "[C_64_128_256] Epoch [27/100] - Train Loss: 0.0325\n",
      "[C_64_128_256] Epoch [28/100] - Train Loss: 0.0284\n",
      "[C_64_128_256] Epoch [29/100] - Train Loss: 0.0221\n",
      "[C_64_128_256] Epoch [30/100] - Train Loss: 0.0179\n",
      "[C_64_128_256] Epoch [31/100] - Train Loss: 0.0165\n",
      "[C_64_128_256] Epoch [32/100] - Train Loss: 0.0143\n",
      "[C_64_128_256] Epoch [33/100] - Train Loss: 0.0098\n",
      "[C_64_128_256] Epoch [34/100] - Train Loss: 0.0071\n",
      "[C_64_128_256] Epoch [35/100] - Train Loss: 0.0054\n",
      "[C_64_128_256] Epoch [36/100] - Train Loss: 0.0043\n",
      "[C_64_128_256] Epoch [37/100] - Train Loss: 0.0043\n",
      "[C_64_128_256] Epoch [38/100] - Train Loss: 0.0029\n",
      "[C_64_128_256] Epoch [39/100] - Train Loss: 0.0024\n",
      "[C_64_128_256] Epoch [40/100] - Train Loss: 0.0021\n",
      "[C_64_128_256] Epoch [41/100] - Train Loss: 0.0018\n",
      "[C_64_128_256] Epoch [42/100] - Train Loss: 0.0016\n",
      "[C_64_128_256] Epoch [43/100] - Train Loss: 0.0015\n",
      "[C_64_128_256] Epoch [44/100] - Train Loss: 0.0013\n",
      "[C_64_128_256] Epoch [45/100] - Train Loss: 0.0013\n",
      "[C_64_128_256] Epoch [46/100] - Train Loss: 0.0012\n",
      "[C_64_128_256] Epoch [47/100] - Train Loss: 0.0011\n",
      "[C_64_128_256] Epoch [48/100] - Train Loss: 0.0011\n",
      "[C_64_128_256] Epoch [49/100] - Train Loss: 0.0010\n",
      "[C_64_128_256] Epoch [50/100] - Train Loss: 0.0010\n",
      "[C_64_128_256] Epoch [51/100] - Train Loss: 0.0009\n",
      "[C_64_128_256] Epoch [52/100] - Train Loss: 0.0009\n",
      "[C_64_128_256] Epoch [53/100] - Train Loss: 0.0008\n",
      "[C_64_128_256] Epoch [54/100] - Train Loss: 0.0008\n",
      "[C_64_128_256] Epoch [55/100] - Train Loss: 0.0008\n",
      "[C_64_128_256] Epoch [56/100] - Train Loss: 0.0008\n",
      "[C_64_128_256] Epoch [57/100] - Train Loss: 0.0007\n",
      "[C_64_128_256] Epoch [58/100] - Train Loss: 0.0007\n",
      "[C_64_128_256] Epoch [59/100] - Train Loss: 0.0007\n",
      "[C_64_128_256] Epoch [60/100] - Train Loss: 0.0007\n",
      "[C_64_128_256] Epoch [61/100] - Train Loss: 0.0007\n",
      "[C_64_128_256] Epoch [62/100] - Train Loss: 0.0006\n",
      "[C_64_128_256] Epoch [63/100] - Train Loss: 0.0006\n",
      "[C_64_128_256] Epoch [64/100] - Train Loss: 0.0006\n",
      "[C_64_128_256] Epoch [65/100] - Train Loss: 0.0006\n",
      "[C_64_128_256] Epoch [66/100] - Train Loss: 0.0006\n",
      "[C_64_128_256] Epoch [67/100] - Train Loss: 0.0006\n",
      "[C_64_128_256] Epoch [68/100] - Train Loss: 0.0006\n",
      "[C_64_128_256] Epoch [69/100] - Train Loss: 0.0006\n",
      "[C_64_128_256] Epoch [70/100] - Train Loss: 0.0006\n",
      "[C_64_128_256] Epoch [71/100] - Train Loss: 0.0006\n",
      "[C_64_128_256] Epoch [72/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [73/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [74/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [75/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [76/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [77/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [78/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [79/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [80/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [81/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [82/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [83/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [84/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [85/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [86/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [87/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [88/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [89/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [90/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [91/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [92/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [93/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [94/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [95/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [96/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [97/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [98/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [99/100] - Train Loss: 0.0005\n",
      "[C_64_128_256] Epoch [100/100] - Train Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Set C models:  67%|█████████▎    | 10/15 [2:32:49<1:44:36, 1255.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[C_64_128_512] parameters: 3291402\n",
      "[C_64_128_512] Epoch [1/100] - Train Loss: 0.5944\n",
      "[C_64_128_512] Epoch [2/100] - Train Loss: 0.3435\n",
      "[C_64_128_512] Epoch [3/100] - Train Loss: 0.2959\n",
      "[C_64_128_512] Epoch [4/100] - Train Loss: 0.2669\n",
      "[C_64_128_512] Epoch [5/100] - Train Loss: 0.2398\n",
      "[C_64_128_512] Epoch [6/100] - Train Loss: 0.2211\n",
      "[C_64_128_512] Epoch [7/100] - Train Loss: 0.2068\n",
      "[C_64_128_512] Epoch [8/100] - Train Loss: 0.1931\n",
      "[C_64_128_512] Epoch [9/100] - Train Loss: 0.1804\n",
      "[C_64_128_512] Epoch [10/100] - Train Loss: 0.1657\n",
      "[C_64_128_512] Epoch [11/100] - Train Loss: 0.1541\n",
      "[C_64_128_512] Epoch [12/100] - Train Loss: 0.1451\n",
      "[C_64_128_512] Epoch [13/100] - Train Loss: 0.1332\n",
      "[C_64_128_512] Epoch [14/100] - Train Loss: 0.1216\n",
      "[C_64_128_512] Epoch [15/100] - Train Loss: 0.1123\n",
      "[C_64_128_512] Epoch [16/100] - Train Loss: 0.1034\n",
      "[C_64_128_512] Epoch [17/100] - Train Loss: 0.0911\n",
      "[C_64_128_512] Epoch [18/100] - Train Loss: 0.0831\n",
      "[C_64_128_512] Epoch [19/100] - Train Loss: 0.0738\n",
      "[C_64_128_512] Epoch [20/100] - Train Loss: 0.0670\n",
      "[C_64_128_512] Epoch [21/100] - Train Loss: 0.0610\n",
      "[C_64_128_512] Epoch [22/100] - Train Loss: 0.0505\n",
      "[C_64_128_512] Epoch [23/100] - Train Loss: 0.0448\n",
      "[C_64_128_512] Epoch [24/100] - Train Loss: 0.0397\n",
      "[C_64_128_512] Epoch [25/100] - Train Loss: 0.0331\n",
      "[C_64_128_512] Epoch [26/100] - Train Loss: 0.0270\n",
      "[C_64_128_512] Epoch [27/100] - Train Loss: 0.0247\n",
      "[C_64_128_512] Epoch [28/100] - Train Loss: 0.0196\n",
      "[C_64_128_512] Epoch [29/100] - Train Loss: 0.0164\n",
      "[C_64_128_512] Epoch [30/100] - Train Loss: 0.0134\n",
      "[C_64_128_512] Epoch [31/100] - Train Loss: 0.0100\n",
      "[C_64_128_512] Epoch [32/100] - Train Loss: 0.0109\n",
      "[C_64_128_512] Epoch [33/100] - Train Loss: 0.0072\n",
      "[C_64_128_512] Epoch [34/100] - Train Loss: 0.0053\n",
      "[C_64_128_512] Epoch [35/100] - Train Loss: 0.0041\n",
      "[C_64_128_512] Epoch [36/100] - Train Loss: 0.0028\n",
      "[C_64_128_512] Epoch [37/100] - Train Loss: 0.0024\n",
      "[C_64_128_512] Epoch [38/100] - Train Loss: 0.0021\n",
      "[C_64_128_512] Epoch [39/100] - Train Loss: 0.0017\n",
      "[C_64_128_512] Epoch [40/100] - Train Loss: 0.0016\n",
      "[C_64_128_512] Epoch [41/100] - Train Loss: 0.0013\n",
      "[C_64_128_512] Epoch [42/100] - Train Loss: 0.0012\n",
      "[C_64_128_512] Epoch [43/100] - Train Loss: 0.0012\n",
      "[C_64_128_512] Epoch [44/100] - Train Loss: 0.0011\n",
      "[C_64_128_512] Epoch [45/100] - Train Loss: 0.0010\n",
      "[C_64_128_512] Epoch [46/100] - Train Loss: 0.0010\n",
      "[C_64_128_512] Epoch [47/100] - Train Loss: 0.0009\n",
      "[C_64_128_512] Epoch [48/100] - Train Loss: 0.0009\n",
      "[C_64_128_512] Epoch [49/100] - Train Loss: 0.0008\n",
      "[C_64_128_512] Epoch [50/100] - Train Loss: 0.0008\n",
      "[C_64_128_512] Epoch [51/100] - Train Loss: 0.0008\n",
      "[C_64_128_512] Epoch [52/100] - Train Loss: 0.0007\n",
      "[C_64_128_512] Epoch [53/100] - Train Loss: 0.0007\n",
      "[C_64_128_512] Epoch [54/100] - Train Loss: 0.0007\n",
      "[C_64_128_512] Epoch [55/100] - Train Loss: 0.0007\n",
      "[C_64_128_512] Epoch [56/100] - Train Loss: 0.0006\n",
      "[C_64_128_512] Epoch [57/100] - Train Loss: 0.0006\n",
      "[C_64_128_512] Epoch [58/100] - Train Loss: 0.0006\n",
      "[C_64_128_512] Epoch [59/100] - Train Loss: 0.0006\n",
      "[C_64_128_512] Epoch [60/100] - Train Loss: 0.0006\n",
      "[C_64_128_512] Epoch [61/100] - Train Loss: 0.0006\n",
      "[C_64_128_512] Epoch [62/100] - Train Loss: 0.0006\n",
      "[C_64_128_512] Epoch [63/100] - Train Loss: 0.0005\n",
      "[C_64_128_512] Epoch [64/100] - Train Loss: 0.0005\n",
      "[C_64_128_512] Epoch [65/100] - Train Loss: 0.0005\n",
      "[C_64_128_512] Epoch [66/100] - Train Loss: 0.0005\n",
      "[C_64_128_512] Epoch [67/100] - Train Loss: 0.0005\n",
      "[C_64_128_512] Epoch [68/100] - Train Loss: 0.0005\n",
      "[C_64_128_512] Epoch [69/100] - Train Loss: 0.0005\n",
      "[C_64_128_512] Epoch [70/100] - Train Loss: 0.0005\n",
      "[C_64_128_512] Epoch [71/100] - Train Loss: 0.0005\n",
      "[C_64_128_512] Epoch [72/100] - Train Loss: 0.0005\n",
      "[C_64_128_512] Epoch [73/100] - Train Loss: 0.0005\n",
      "[C_64_128_512] Epoch [74/100] - Train Loss: 0.0005\n",
      "[C_64_128_512] Epoch [75/100] - Train Loss: 0.0005\n",
      "[C_64_128_512] Epoch [76/100] - Train Loss: 0.0005\n",
      "[C_64_128_512] Epoch [77/100] - Train Loss: 0.0005\n",
      "[C_64_128_512] Epoch [78/100] - Train Loss: 0.0005\n",
      "[C_64_128_512] Epoch [79/100] - Train Loss: 0.0005\n",
      "[C_64_128_512] Epoch [80/100] - Train Loss: 0.0004\n",
      "[C_64_128_512] Epoch [81/100] - Train Loss: 0.0004\n",
      "[C_64_128_512] Epoch [82/100] - Train Loss: 0.0004\n",
      "[C_64_128_512] Epoch [83/100] - Train Loss: 0.0004\n",
      "[C_64_128_512] Epoch [84/100] - Train Loss: 0.0004\n",
      "[C_64_128_512] Epoch [85/100] - Train Loss: 0.0004\n",
      "[C_64_128_512] Epoch [86/100] - Train Loss: 0.0004\n",
      "[C_64_128_512] Epoch [87/100] - Train Loss: 0.0004\n",
      "[C_64_128_512] Epoch [88/100] - Train Loss: 0.0004\n",
      "[C_64_128_512] Epoch [89/100] - Train Loss: 0.0004\n",
      "[C_64_128_512] Epoch [90/100] - Train Loss: 0.0004\n",
      "[C_64_128_512] Epoch [91/100] - Train Loss: 0.0004\n",
      "[C_64_128_512] Epoch [92/100] - Train Loss: 0.0004\n",
      "[C_64_128_512] Epoch [93/100] - Train Loss: 0.0004\n",
      "[C_64_128_512] Epoch [94/100] - Train Loss: 0.0004\n",
      "[C_64_128_512] Epoch [95/100] - Train Loss: 0.0004\n",
      "[C_64_128_512] Epoch [96/100] - Train Loss: 0.0004\n",
      "[C_64_128_512] Epoch [97/100] - Train Loss: 0.0004\n",
      "[C_64_128_512] Epoch [98/100] - Train Loss: 0.0004\n",
      "[C_64_128_512] Epoch [99/100] - Train Loss: 0.0004\n",
      "[C_64_128_512] Epoch [100/100] - Train Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Set C models:  73%|██████████▎   | 11/15 [3:02:11<1:34:01, 1410.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[C_128_256_512] parameters: 6724618\n",
      "[C_128_256_512] Epoch [1/100] - Train Loss: 0.5494\n",
      "[C_128_256_512] Epoch [2/100] - Train Loss: 0.3290\n",
      "[C_128_256_512] Epoch [3/100] - Train Loss: 0.2831\n",
      "[C_128_256_512] Epoch [4/100] - Train Loss: 0.2478\n",
      "[C_128_256_512] Epoch [5/100] - Train Loss: 0.2294\n",
      "[C_128_256_512] Epoch [6/100] - Train Loss: 0.2068\n",
      "[C_128_256_512] Epoch [7/100] - Train Loss: 0.1911\n",
      "[C_128_256_512] Epoch [8/100] - Train Loss: 0.1756\n",
      "[C_128_256_512] Epoch [9/100] - Train Loss: 0.1622\n",
      "[C_128_256_512] Epoch [10/100] - Train Loss: 0.1501\n",
      "[C_128_256_512] Epoch [11/100] - Train Loss: 0.1356\n",
      "[C_128_256_512] Epoch [12/100] - Train Loss: 0.1256\n",
      "[C_128_256_512] Epoch [13/100] - Train Loss: 0.1124\n",
      "[C_128_256_512] Epoch [14/100] - Train Loss: 0.1001\n",
      "[C_128_256_512] Epoch [15/100] - Train Loss: 0.0908\n",
      "[C_128_256_512] Epoch [16/100] - Train Loss: 0.0792\n",
      "[C_128_256_512] Epoch [17/100] - Train Loss: 0.0689\n",
      "[C_128_256_512] Epoch [18/100] - Train Loss: 0.0614\n",
      "[C_128_256_512] Epoch [19/100] - Train Loss: 0.0529\n",
      "[C_128_256_512] Epoch [20/100] - Train Loss: 0.0450\n",
      "[C_128_256_512] Epoch [21/100] - Train Loss: 0.0376\n",
      "[C_128_256_512] Epoch [22/100] - Train Loss: 0.0352\n",
      "[C_128_256_512] Epoch [23/100] - Train Loss: 0.0278\n",
      "[C_128_256_512] Epoch [24/100] - Train Loss: 0.0229\n",
      "[C_128_256_512] Epoch [25/100] - Train Loss: 0.0185\n",
      "[C_128_256_512] Epoch [26/100] - Train Loss: 0.0162\n",
      "[C_128_256_512] Epoch [27/100] - Train Loss: 0.0143\n",
      "[C_128_256_512] Epoch [28/100] - Train Loss: 0.0099\n",
      "[C_128_256_512] Epoch [29/100] - Train Loss: 0.0069\n",
      "[C_128_256_512] Epoch [30/100] - Train Loss: 0.0054\n",
      "[C_128_256_512] Epoch [31/100] - Train Loss: 0.0041\n",
      "[C_128_256_512] Epoch [32/100] - Train Loss: 0.0043\n",
      "[C_128_256_512] Epoch [33/100] - Train Loss: 0.0027\n",
      "[C_128_256_512] Epoch [34/100] - Train Loss: 0.0021\n",
      "[C_128_256_512] Epoch [35/100] - Train Loss: 0.0019\n",
      "[C_128_256_512] Epoch [36/100] - Train Loss: 0.0016\n",
      "[C_128_256_512] Epoch [37/100] - Train Loss: 0.0015\n",
      "[C_128_256_512] Epoch [38/100] - Train Loss: 0.0013\n",
      "[C_128_256_512] Epoch [39/100] - Train Loss: 0.0011\n",
      "[C_128_256_512] Epoch [40/100] - Train Loss: 0.0011\n",
      "[C_128_256_512] Epoch [41/100] - Train Loss: 0.0010\n",
      "[C_128_256_512] Epoch [42/100] - Train Loss: 0.0009\n",
      "[C_128_256_512] Epoch [43/100] - Train Loss: 0.0009\n",
      "[C_128_256_512] Epoch [44/100] - Train Loss: 0.0008\n",
      "[C_128_256_512] Epoch [45/100] - Train Loss: 0.0008\n",
      "[C_128_256_512] Epoch [46/100] - Train Loss: 0.0008\n",
      "[C_128_256_512] Epoch [47/100] - Train Loss: 0.0007\n",
      "[C_128_256_512] Epoch [48/100] - Train Loss: 0.0007\n",
      "[C_128_256_512] Epoch [49/100] - Train Loss: 0.0007\n",
      "[C_128_256_512] Epoch [50/100] - Train Loss: 0.0006\n",
      "[C_128_256_512] Epoch [51/100] - Train Loss: 0.0006\n",
      "[C_128_256_512] Epoch [52/100] - Train Loss: 0.0006\n",
      "[C_128_256_512] Epoch [53/100] - Train Loss: 0.0006\n",
      "[C_128_256_512] Epoch [54/100] - Train Loss: 0.0006\n",
      "[C_128_256_512] Epoch [55/100] - Train Loss: 0.0006\n",
      "[C_128_256_512] Epoch [56/100] - Train Loss: 0.0005\n",
      "[C_128_256_512] Epoch [57/100] - Train Loss: 0.0005\n",
      "[C_128_256_512] Epoch [58/100] - Train Loss: 0.0005\n",
      "[C_128_256_512] Epoch [59/100] - Train Loss: 0.0005\n",
      "[C_128_256_512] Epoch [60/100] - Train Loss: 0.0005\n",
      "[C_128_256_512] Epoch [61/100] - Train Loss: 0.0005\n",
      "[C_128_256_512] Epoch [62/100] - Train Loss: 0.0005\n",
      "[C_128_256_512] Epoch [63/100] - Train Loss: 0.0005\n",
      "[C_128_256_512] Epoch [64/100] - Train Loss: 0.0005\n",
      "[C_128_256_512] Epoch [65/100] - Train Loss: 0.0005\n",
      "[C_128_256_512] Epoch [66/100] - Train Loss: 0.0005\n",
      "[C_128_256_512] Epoch [67/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [68/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [69/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [70/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [71/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [72/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [73/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [74/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [75/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [76/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [77/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [78/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [79/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [80/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [81/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [82/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [83/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [84/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [85/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [86/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [87/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [88/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [89/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [90/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [91/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [92/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [93/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [94/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [95/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [96/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [97/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [98/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [99/100] - Train Loss: 0.0004\n",
      "[C_128_256_512] Epoch [100/100] - Train Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Set C models:  80%|███████████▏  | 12/15 [4:07:27<1:48:38, 2172.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[C_128_256_1024] parameters: 13152778\n",
      "[C_128_256_1024] Epoch [1/100] - Train Loss: 0.5506\n",
      "[C_128_256_1024] Epoch [2/100] - Train Loss: 0.3295\n",
      "[C_128_256_1024] Epoch [3/100] - Train Loss: 0.2807\n",
      "[C_128_256_1024] Epoch [4/100] - Train Loss: 0.2514\n",
      "[C_128_256_1024] Epoch [5/100] - Train Loss: 0.2286\n",
      "[C_128_256_1024] Epoch [6/100] - Train Loss: 0.2075\n",
      "[C_128_256_1024] Epoch [7/100] - Train Loss: 0.1909\n",
      "[C_128_256_1024] Epoch [8/100] - Train Loss: 0.1749\n",
      "[C_128_256_1024] Epoch [9/100] - Train Loss: 0.1630\n",
      "[C_128_256_1024] Epoch [10/100] - Train Loss: 0.1472\n",
      "[C_128_256_1024] Epoch [11/100] - Train Loss: 0.1353\n",
      "[C_128_256_1024] Epoch [12/100] - Train Loss: 0.1216\n",
      "[C_128_256_1024] Epoch [13/100] - Train Loss: 0.1098\n",
      "[C_128_256_1024] Epoch [14/100] - Train Loss: 0.1000\n",
      "[C_128_256_1024] Epoch [15/100] - Train Loss: 0.0868\n",
      "[C_128_256_1024] Epoch [16/100] - Train Loss: 0.0794\n",
      "[C_128_256_1024] Epoch [17/100] - Train Loss: 0.0694\n",
      "[C_128_256_1024] Epoch [18/100] - Train Loss: 0.0612\n",
      "[C_128_256_1024] Epoch [19/100] - Train Loss: 0.0525\n",
      "[C_128_256_1024] Epoch [20/100] - Train Loss: 0.0442\n",
      "[C_128_256_1024] Epoch [21/100] - Train Loss: 0.0385\n",
      "[C_128_256_1024] Epoch [22/100] - Train Loss: 0.0307\n",
      "[C_128_256_1024] Epoch [23/100] - Train Loss: 0.0260\n",
      "[C_128_256_1024] Epoch [24/100] - Train Loss: 0.0190\n",
      "[C_128_256_1024] Epoch [25/100] - Train Loss: 0.0182\n",
      "[C_128_256_1024] Epoch [26/100] - Train Loss: 0.0144\n",
      "[C_128_256_1024] Epoch [27/100] - Train Loss: 0.0125\n",
      "[C_128_256_1024] Epoch [28/100] - Train Loss: 0.0096\n",
      "[C_128_256_1024] Epoch [29/100] - Train Loss: 0.0067\n",
      "[C_128_256_1024] Epoch [30/100] - Train Loss: 0.0047\n",
      "[C_128_256_1024] Epoch [31/100] - Train Loss: 0.0035\n",
      "[C_128_256_1024] Epoch [32/100] - Train Loss: 0.0026\n",
      "[C_128_256_1024] Epoch [33/100] - Train Loss: 0.0021\n",
      "[C_128_256_1024] Epoch [34/100] - Train Loss: 0.0018\n",
      "[C_128_256_1024] Epoch [35/100] - Train Loss: 0.0017\n",
      "[C_128_256_1024] Epoch [36/100] - Train Loss: 0.0015\n",
      "[C_128_256_1024] Epoch [37/100] - Train Loss: 0.0013\n",
      "[C_128_256_1024] Epoch [38/100] - Train Loss: 0.0012\n",
      "[C_128_256_1024] Epoch [39/100] - Train Loss: 0.0011\n",
      "[C_128_256_1024] Epoch [40/100] - Train Loss: 0.0010\n",
      "[C_128_256_1024] Epoch [41/100] - Train Loss: 0.0010\n",
      "[C_128_256_1024] Epoch [42/100] - Train Loss: 0.0009\n",
      "[C_128_256_1024] Epoch [43/100] - Train Loss: 0.0008\n",
      "[C_128_256_1024] Epoch [44/100] - Train Loss: 0.0008\n",
      "[C_128_256_1024] Epoch [45/100] - Train Loss: 0.0008\n",
      "[C_128_256_1024] Epoch [46/100] - Train Loss: 0.0007\n",
      "[C_128_256_1024] Epoch [47/100] - Train Loss: 0.0007\n",
      "[C_128_256_1024] Epoch [48/100] - Train Loss: 0.0007\n",
      "[C_128_256_1024] Epoch [49/100] - Train Loss: 0.0006\n",
      "[C_128_256_1024] Epoch [50/100] - Train Loss: 0.0006\n",
      "[C_128_256_1024] Epoch [51/100] - Train Loss: 0.0006\n",
      "[C_128_256_1024] Epoch [52/100] - Train Loss: 0.0006\n",
      "[C_128_256_1024] Epoch [53/100] - Train Loss: 0.0006\n",
      "[C_128_256_1024] Epoch [54/100] - Train Loss: 0.0005\n",
      "[C_128_256_1024] Epoch [55/100] - Train Loss: 0.0005\n",
      "[C_128_256_1024] Epoch [56/100] - Train Loss: 0.0005\n",
      "[C_128_256_1024] Epoch [57/100] - Train Loss: 0.0005\n",
      "[C_128_256_1024] Epoch [58/100] - Train Loss: 0.0005\n",
      "[C_128_256_1024] Epoch [59/100] - Train Loss: 0.0005\n",
      "[C_128_256_1024] Epoch [60/100] - Train Loss: 0.0005\n",
      "[C_128_256_1024] Epoch [61/100] - Train Loss: 0.0005\n",
      "[C_128_256_1024] Epoch [62/100] - Train Loss: 0.0005\n",
      "[C_128_256_1024] Epoch [63/100] - Train Loss: 0.0005\n",
      "[C_128_256_1024] Epoch [64/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [65/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [66/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [67/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [68/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [69/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [70/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [71/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [72/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [73/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [74/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [75/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [76/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [77/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [78/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [79/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [80/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [81/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [82/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [83/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [84/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [85/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [86/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [87/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [88/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [89/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [90/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [91/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [92/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [93/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [94/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [95/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [96/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [97/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [98/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [99/100] - Train Loss: 0.0004\n",
      "[C_128_256_1024] Epoch [100/100] - Train Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Set C models:  87%|████████████▏ | 13/15 [5:20:21<1:34:39, 2839.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[C_256_512_1024] parameters: 26884106\n",
      "[C_256_512_1024] Epoch [1/100] - Train Loss: 0.5184\n",
      "[C_256_512_1024] Epoch [2/100] - Train Loss: 0.3130\n",
      "[C_256_512_1024] Epoch [3/100] - Train Loss: 0.2687\n",
      "[C_256_512_1024] Epoch [4/100] - Train Loss: 0.2402\n",
      "[C_256_512_1024] Epoch [5/100] - Train Loss: 0.2164\n",
      "[C_256_512_1024] Epoch [6/100] - Train Loss: 0.1943\n",
      "[C_256_512_1024] Epoch [7/100] - Train Loss: 0.1774\n",
      "[C_256_512_1024] Epoch [8/100] - Train Loss: 0.1577\n",
      "[C_256_512_1024] Epoch [9/100] - Train Loss: 0.1446\n",
      "[C_256_512_1024] Epoch [10/100] - Train Loss: 0.1325\n",
      "[C_256_512_1024] Epoch [11/100] - Train Loss: 0.1165\n",
      "[C_256_512_1024] Epoch [12/100] - Train Loss: 0.1036\n",
      "[C_256_512_1024] Epoch [13/100] - Train Loss: 0.0946\n",
      "[C_256_512_1024] Epoch [14/100] - Train Loss: 0.0786\n",
      "[C_256_512_1024] Epoch [15/100] - Train Loss: 0.0699\n",
      "[C_256_512_1024] Epoch [16/100] - Train Loss: 0.0601\n",
      "[C_256_512_1024] Epoch [17/100] - Train Loss: 0.0515\n",
      "[C_256_512_1024] Epoch [18/100] - Train Loss: 0.0417\n",
      "[C_256_512_1024] Epoch [19/100] - Train Loss: 0.0352\n",
      "[C_256_512_1024] Epoch [20/100] - Train Loss: 0.0291\n",
      "[C_256_512_1024] Epoch [21/100] - Train Loss: 0.0234\n",
      "[C_256_512_1024] Epoch [22/100] - Train Loss: 0.0189\n",
      "[C_256_512_1024] Epoch [23/100] - Train Loss: 0.0172\n",
      "[C_256_512_1024] Epoch [24/100] - Train Loss: 0.0112\n",
      "[C_256_512_1024] Epoch [25/100] - Train Loss: 0.0114\n",
      "[C_256_512_1024] Epoch [26/100] - Train Loss: 0.0080\n",
      "[C_256_512_1024] Epoch [27/100] - Train Loss: 0.0052\n",
      "[C_256_512_1024] Epoch [28/100] - Train Loss: 0.0035\n",
      "[C_256_512_1024] Epoch [29/100] - Train Loss: 0.0025\n",
      "[C_256_512_1024] Epoch [30/100] - Train Loss: 0.0023\n",
      "[C_256_512_1024] Epoch [31/100] - Train Loss: 0.0018\n",
      "[C_256_512_1024] Epoch [32/100] - Train Loss: 0.0016\n",
      "[C_256_512_1024] Epoch [33/100] - Train Loss: 0.0013\n",
      "[C_256_512_1024] Epoch [34/100] - Train Loss: 0.0013\n",
      "[C_256_512_1024] Epoch [35/100] - Train Loss: 0.0011\n",
      "[C_256_512_1024] Epoch [36/100] - Train Loss: 0.0010\n",
      "[C_256_512_1024] Epoch [37/100] - Train Loss: 0.0009\n",
      "[C_256_512_1024] Epoch [38/100] - Train Loss: 0.0009\n",
      "[C_256_512_1024] Epoch [39/100] - Train Loss: 0.0008\n",
      "[C_256_512_1024] Epoch [40/100] - Train Loss: 0.0008\n",
      "[C_256_512_1024] Epoch [41/100] - Train Loss: 0.0007\n",
      "[C_256_512_1024] Epoch [42/100] - Train Loss: 0.0007\n",
      "[C_256_512_1024] Epoch [43/100] - Train Loss: 0.0007\n",
      "[C_256_512_1024] Epoch [44/100] - Train Loss: 0.0006\n",
      "[C_256_512_1024] Epoch [45/100] - Train Loss: 0.0006\n",
      "[C_256_512_1024] Epoch [46/100] - Train Loss: 0.0006\n",
      "[C_256_512_1024] Epoch [47/100] - Train Loss: 0.0006\n",
      "[C_256_512_1024] Epoch [48/100] - Train Loss: 0.0005\n",
      "[C_256_512_1024] Epoch [49/100] - Train Loss: 0.0005\n",
      "[C_256_512_1024] Epoch [50/100] - Train Loss: 0.0005\n",
      "[C_256_512_1024] Epoch [51/100] - Train Loss: 0.0005\n",
      "[C_256_512_1024] Epoch [52/100] - Train Loss: 0.0005\n",
      "[C_256_512_1024] Epoch [53/100] - Train Loss: 0.0005\n",
      "[C_256_512_1024] Epoch [54/100] - Train Loss: 0.0005\n",
      "[C_256_512_1024] Epoch [55/100] - Train Loss: 0.0004\n",
      "[C_256_512_1024] Epoch [56/100] - Train Loss: 0.0004\n",
      "[C_256_512_1024] Epoch [57/100] - Train Loss: 0.0004\n",
      "[C_256_512_1024] Epoch [58/100] - Train Loss: 0.0004\n",
      "[C_256_512_1024] Epoch [59/100] - Train Loss: 0.0004\n",
      "[C_256_512_1024] Epoch [60/100] - Train Loss: 0.0004\n",
      "[C_256_512_1024] Epoch [61/100] - Train Loss: 0.0004\n",
      "[C_256_512_1024] Epoch [62/100] - Train Loss: 0.0004\n",
      "[C_256_512_1024] Epoch [63/100] - Train Loss: 0.0004\n",
      "[C_256_512_1024] Epoch [64/100] - Train Loss: 0.0004\n",
      "[C_256_512_1024] Epoch [65/100] - Train Loss: 0.0004\n",
      "[C_256_512_1024] Epoch [66/100] - Train Loss: 0.0004\n",
      "[C_256_512_1024] Epoch [67/100] - Train Loss: 0.0004\n",
      "[C_256_512_1024] Epoch [68/100] - Train Loss: 0.0004\n",
      "[C_256_512_1024] Epoch [69/100] - Train Loss: 0.0004\n",
      "[C_256_512_1024] Epoch [70/100] - Train Loss: 0.0004\n",
      "[C_256_512_1024] Epoch [71/100] - Train Loss: 0.0004\n",
      "[C_256_512_1024] Epoch [72/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [73/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [74/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [75/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [76/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [77/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [78/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [79/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [80/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [81/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [82/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [83/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [84/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [85/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [86/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [87/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [88/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [89/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [90/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [91/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [92/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [93/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [94/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [95/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [96/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [97/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [98/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [99/100] - Train Loss: 0.0003\n",
      "[C_256_512_1024] Epoch [100/100] - Train Loss: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Set C models:  93%|█████████████ | 14/15 [8:16:00<1:26:05, 5165.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[C_512_1024_1024] parameters: 56116234\n",
      "[C_512_1024_1024] Epoch [1/100] - Train Loss: 0.4880\n",
      "[C_512_1024_1024] Epoch [2/100] - Train Loss: 0.3032\n",
      "[C_512_1024_1024] Epoch [3/100] - Train Loss: 0.2566\n",
      "[C_512_1024_1024] Epoch [4/100] - Train Loss: 0.2289\n",
      "[C_512_1024_1024] Epoch [5/100] - Train Loss: 0.2000\n",
      "[C_512_1024_1024] Epoch [6/100] - Train Loss: 0.1807\n",
      "[C_512_1024_1024] Epoch [7/100] - Train Loss: 0.1608\n",
      "[C_512_1024_1024] Epoch [8/100] - Train Loss: 0.1428\n",
      "[C_512_1024_1024] Epoch [9/100] - Train Loss: 0.1287\n",
      "[C_512_1024_1024] Epoch [10/100] - Train Loss: 0.1134\n",
      "[C_512_1024_1024] Epoch [11/100] - Train Loss: 0.0989\n",
      "[C_512_1024_1024] Epoch [12/100] - Train Loss: 0.0878\n",
      "[C_512_1024_1024] Epoch [13/100] - Train Loss: 0.0750\n",
      "[C_512_1024_1024] Epoch [14/100] - Train Loss: 0.0622\n",
      "[C_512_1024_1024] Epoch [15/100] - Train Loss: 0.0519\n",
      "[C_512_1024_1024] Epoch [16/100] - Train Loss: 0.0441\n",
      "[C_512_1024_1024] Epoch [17/100] - Train Loss: 0.0364\n",
      "[C_512_1024_1024] Epoch [18/100] - Train Loss: 0.0318\n",
      "[C_512_1024_1024] Epoch [19/100] - Train Loss: 0.0229\n",
      "[C_512_1024_1024] Epoch [20/100] - Train Loss: 0.0173\n",
      "[C_512_1024_1024] Epoch [21/100] - Train Loss: 0.0169\n",
      "[C_512_1024_1024] Epoch [22/100] - Train Loss: 0.0111\n",
      "[C_512_1024_1024] Epoch [23/100] - Train Loss: 0.0069\n",
      "[C_512_1024_1024] Epoch [24/100] - Train Loss: 0.0051\n",
      "[C_512_1024_1024] Epoch [25/100] - Train Loss: 0.0038\n",
      "[C_512_1024_1024] Epoch [26/100] - Train Loss: 0.0040\n",
      "[C_512_1024_1024] Epoch [27/100] - Train Loss: 0.0020\n",
      "[C_512_1024_1024] Epoch [28/100] - Train Loss: 0.0017\n",
      "[C_512_1024_1024] Epoch [29/100] - Train Loss: 0.0013\n",
      "[C_512_1024_1024] Epoch [30/100] - Train Loss: 0.0012\n",
      "[C_512_1024_1024] Epoch [31/100] - Train Loss: 0.0010\n",
      "[C_512_1024_1024] Epoch [32/100] - Train Loss: 0.0009\n",
      "[C_512_1024_1024] Epoch [33/100] - Train Loss: 0.0009\n",
      "[C_512_1024_1024] Epoch [34/100] - Train Loss: 0.0008\n",
      "[C_512_1024_1024] Epoch [35/100] - Train Loss: 0.0007\n",
      "[C_512_1024_1024] Epoch [36/100] - Train Loss: 0.0007\n",
      "[C_512_1024_1024] Epoch [37/100] - Train Loss: 0.0007\n",
      "[C_512_1024_1024] Epoch [38/100] - Train Loss: 0.0006\n",
      "[C_512_1024_1024] Epoch [39/100] - Train Loss: 0.0006\n",
      "[C_512_1024_1024] Epoch [40/100] - Train Loss: 0.0006\n",
      "[C_512_1024_1024] Epoch [41/100] - Train Loss: 0.0005\n",
      "[C_512_1024_1024] Epoch [42/100] - Train Loss: 0.0005\n",
      "[C_512_1024_1024] Epoch [43/100] - Train Loss: 0.0005\n",
      "[C_512_1024_1024] Epoch [44/100] - Train Loss: 0.0005\n",
      "[C_512_1024_1024] Epoch [45/100] - Train Loss: 0.0005\n",
      "[C_512_1024_1024] Epoch [46/100] - Train Loss: 0.0004\n",
      "[C_512_1024_1024] Epoch [47/100] - Train Loss: 0.0004\n",
      "[C_512_1024_1024] Epoch [48/100] - Train Loss: 0.0004\n",
      "[C_512_1024_1024] Epoch [49/100] - Train Loss: 0.0004\n",
      "[C_512_1024_1024] Epoch [50/100] - Train Loss: 0.0004\n",
      "[C_512_1024_1024] Epoch [51/100] - Train Loss: 0.0004\n",
      "[C_512_1024_1024] Epoch [52/100] - Train Loss: 0.0004\n",
      "[C_512_1024_1024] Epoch [53/100] - Train Loss: 0.0004\n",
      "[C_512_1024_1024] Epoch [54/100] - Train Loss: 0.0004\n",
      "[C_512_1024_1024] Epoch [55/100] - Train Loss: 0.0004\n",
      "[C_512_1024_1024] Epoch [56/100] - Train Loss: 0.0004\n",
      "[C_512_1024_1024] Epoch [57/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [58/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [59/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [60/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [61/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [62/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [63/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [64/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [65/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [66/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [67/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [68/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [69/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [70/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [71/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [72/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [73/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [74/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [75/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [76/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [77/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [78/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [79/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [80/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [81/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [82/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [83/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [84/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [85/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [86/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [87/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [88/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [89/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [90/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [91/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [92/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [93/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [94/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [95/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [96/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [97/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [98/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [99/100] - Train Loss: 0.0003\n",
      "[C_512_1024_1024] Epoch [100/100] - Train Loss: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Set C models: 100%|███████████████| 15/15 [19:32:25<00:00, 4689.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Set C summary (sorted by parameter count):\n",
      "                 id    params  train_error  test_error   gen_gap  gscm_score\n",
      "0          C_4_8_16      6794     0.062783      0.0989  0.036117    0.578779\n",
      "1         C_8_16_32     26698     0.010833      0.0969  0.086067    0.794021\n",
      "2         C_8_16_64     52138     0.000333      0.0939  0.093567    0.588089\n",
      "3       C_16_32_128    206922     0.000000      0.0825  0.082500    0.424922\n",
      "5        C_32_64_64    220234     0.000000      0.0770  0.077000    0.374797\n",
      "4       C_16_32_256    409034     0.000000      0.0793  0.079300    0.404404\n",
      "6       C_32_64_128    421642     0.000000      0.0780  0.078000    0.410260\n",
      "7       C_32_64_256    824458     0.000000      0.0754  0.075400    0.388005\n",
      "8      C_64_128_128    878730     0.000000      0.0716  0.071600    0.359211\n",
      "9      C_64_128_256   1682954     0.000000      0.0699  0.069900    0.375746\n",
      "10     C_64_128_512   3291402     0.000000      0.0686  0.068600    0.387114\n",
      "11    C_128_256_512   6724618     0.000000      0.0697  0.069700    0.408139\n",
      "12   C_128_256_1024  13152778     0.000000      0.0684  0.068400    0.444248\n",
      "13   C_256_512_1024  26884106     0.000000      0.0679  0.067900    0.473215\n",
      "14  C_512_1024_1024  56116234     0.000000      0.0695  0.069500    0.542712\n",
      "\n",
      "Set C results saved to 'dissertation_results_set_c.csv'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----------------------------------\n",
    "# 0. Reproducibility and device\n",
    "# ----------------------------------\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    \"\"\"Set random seeds for reproducible experiments.\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def get_device() -> torch.device:\n",
    "    \"\"\"Selects MPS (Apple), CUDA, or CPU.\"\"\"\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "set_seed(42)\n",
    "DEVICE = get_device()\n",
    "print(\"Using device for Set C:\", DEVICE)\n",
    "\n",
    "EPOCHS_C = 100\n",
    "LR_C = 0.01\n",
    "BATCH_SIZE_C = 128\n",
    "\n",
    "# ----------------------------------\n",
    "# 1. Complexity measure helpers\n",
    "# ----------------------------------\n",
    "\n",
    "def calculate_l2_norm(model: nn.Module) -> float:\n",
    "    \"\"\"Computes the Frobenius norm of all weight matrices.\"\"\"\n",
    "    l2_norm = 0.0\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"weight\" in name:\n",
    "            l2_norm += torch.sum(param.detach() ** 2)\n",
    "    return torch.sqrt(l2_norm).item()\n",
    "\n",
    "def calculate_spectral_norm(model: nn.Module) -> float:\n",
    "    \"\"\"Computes the sum of maximum singular values across weight matrices.\"\"\"\n",
    "    spectral_norm_sum = 0.0\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"weight\" in name and param.dim() > 1:\n",
    "            if param.dim() == 4:\n",
    "                W = param.view(param.shape[0], -1)\n",
    "            else:\n",
    "                W = param\n",
    "            try:\n",
    "                if W.numel() > 0:\n",
    "                    _, S, _ = torch.linalg.svd(W, full_matrices=False)\n",
    "                    spectral_norm_sum += S[0].item()\n",
    "            except Exception:\n",
    "                continue\n",
    "    return spectral_norm_sum\n",
    "\n",
    "def calculate_sharpness(\n",
    "    model: nn.Module,\n",
    "    criterion: nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    rho: float = 0.01,\n",
    "    device: torch.device = DEVICE,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Approximates sharpness using a single SAM-style perturbation step.\n",
    "    S(w*) = (L(w* + ε) - L(w*)) / (1 + L(w*)).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    try:\n",
    "        data_batch, target_batch = next(iter(data_loader))\n",
    "    except StopIteration:\n",
    "        return 0.0\n",
    "\n",
    "    data_batch, target_batch = data_batch.to(device), target_batch.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(data_batch)\n",
    "        base_loss = criterion(outputs, target_batch).item()\n",
    "\n",
    "    model.zero_grad()\n",
    "    outputs = model(data_batch)\n",
    "    loss = criterion(outputs, target_batch)\n",
    "    loss.backward()\n",
    "\n",
    "    grad_norm_sq = 0.0\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            grad_norm_sq += torch.sum(p.grad ** 2)\n",
    "    grad_norm = torch.sqrt(grad_norm_sq)\n",
    "    if grad_norm.item() == 0.0:\n",
    "        return 0.0\n",
    "\n",
    "    epsilon_map = {}\n",
    "    for name, p in model.named_parameters():\n",
    "        if p.grad is not None:\n",
    "            eps = (p.grad / grad_norm) * rho\n",
    "            p.data.add_(eps)\n",
    "            epsilon_map[name] = eps\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs_perturbed = model(data_batch)\n",
    "        pert_loss = criterion(outputs_perturbed, target_batch).item()\n",
    "\n",
    "    for name, p in model.named_parameters():\n",
    "        if name in epsilon_map:\n",
    "            p.data.sub_(epsilon_map[name])\n",
    "\n",
    "    sharp = (pert_loss - base_loss) / (1.0 + base_loss)\n",
    "    return max(0.0, sharp)\n",
    "\n",
    "def evaluate_model(\n",
    "    model: nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device = DEVICE,\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"Computes average loss and classification error on a dataset.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            total_loss += loss.item() * data.size(0)\n",
    "\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            correct += (preds == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    error = 1.0 - (correct / total)\n",
    "    return avg_loss, error\n",
    "\n",
    "# ----------------------------------\n",
    "# 2. Model definition (Variable CNN)\n",
    "# ----------------------------------\n",
    "\n",
    "class VariableCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional network for Fashion-MNIST with variable width and depth.\n",
    "    Architecture: Conv -> ReLU -> Pool -> Conv -> ReLU -> Pool -> FC -> FC.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        conv1_filters: int,\n",
    "        conv2_filters: int,\n",
    "        fc1_size: int,\n",
    "        num_classes: int = 10,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, conv1_filters, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(conv1_filters, conv2_filters, kernel_size=3, padding=1)\n",
    "        self.flattened_size = 7 * 7 * conv2_filters\n",
    "        self.fc1 = nn.Linear(self.flattened_size, fc1_size)\n",
    "        self.fc2 = nn.Linear(fc1_size, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self.flattened_size)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# ----------------------------------\n",
    "# 3. Fashion-MNIST loader\n",
    "# ----------------------------------\n",
    "\n",
    "def load_fashion_mnist(\n",
    "    batch_size: int = BATCH_SIZE_C,\n",
    "):\n",
    "    \"\"\"\n",
    "    Loads the Fashion-MNIST dataset with standard normalisation.\n",
    "    Uses the full training and test sets.\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_dataset = datasets.FashionMNIST(\n",
    "        \"./data\", train=True, download=True, transform=transform\n",
    "    )\n",
    "    test_dataset = datasets.FashionMNIST(\n",
    "        \"./data\", train=False, download=True, transform=transform\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "# ----------------------------------\n",
    "# 4. Training for one configuration\n",
    "# ----------------------------------\n",
    "\n",
    "def train_and_evaluate_cnn(\n",
    "    config: dict,\n",
    "    train_loader: DataLoader,\n",
    "    test_loader: DataLoader,\n",
    "    epochs: int = EPOCHS_C,\n",
    "    lr: float = LR_C,\n",
    "    device: torch.device = DEVICE,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Trains a VariableCNN for a given configuration and reports metrics.\n",
    "    \"\"\"\n",
    "    model = VariableCNN(\n",
    "        conv1_filters=config[\"conv1_filters\"],\n",
    "        conv2_filters=config[\"conv2_filters\"],\n",
    "        fc1_size=config[\"fc1_size\"],\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"\\n[{config['id']}] parameters: {total_params}\")\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * data.size(0)\n",
    "\n",
    "        scheduler.step()\n",
    "        avg_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"[{config['id']}] Epoch [{epoch+1}/{epochs}] - Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    train_loss, train_error = evaluate_model(model, train_loader, criterion, device)\n",
    "    test_loss, test_error = evaluate_model(model, test_loader, criterion, device)\n",
    "    gen_gap = test_error - train_error\n",
    "\n",
    "    l2 = calculate_l2_norm(model)\n",
    "    spec = calculate_spectral_norm(model)\n",
    "    sharp = calculate_sharpness(model, criterion, train_loader, device=device)\n",
    "\n",
    "    return {\n",
    "        \"id\": config[\"id\"],\n",
    "        \"params\": total_params,\n",
    "        \"train_error\": train_error,\n",
    "        \"test_error\": test_error,\n",
    "        \"gen_gap\": gen_gap,\n",
    "        \"l2_norm\": l2,\n",
    "        \"spectral_norm\": spec,\n",
    "        \"sharpness\": sharp,\n",
    "    }\n",
    "\n",
    "# ----------------------------------\n",
    "# 5. Architecture configurations\n",
    "# ----------------------------------\n",
    "\n",
    "ARCHITECTURE_CONFIGS = [\n",
    "    {\"id\": \"C_4_8_16\",        \"conv1_filters\": 4,   \"conv2_filters\": 8,   \"fc1_size\": 16},\n",
    "    {\"id\": \"C_8_16_32\",       \"conv1_filters\": 8,   \"conv2_filters\": 16,  \"fc1_size\": 32},\n",
    "    {\"id\": \"C_8_16_64\",       \"conv1_filters\": 8,   \"conv2_filters\": 16,  \"fc1_size\": 64},\n",
    "    {\"id\": \"C_16_32_128\",     \"conv1_filters\": 16,  \"conv2_filters\": 32,  \"fc1_size\": 128},\n",
    "    {\"id\": \"C_16_32_256\",     \"conv1_filters\": 16,  \"conv2_filters\": 32,  \"fc1_size\": 256},\n",
    "    {\"id\": \"C_32_64_64\",      \"conv1_filters\": 32,  \"conv2_filters\": 64,  \"fc1_size\": 64},\n",
    "    {\"id\": \"C_32_64_128\",     \"conv1_filters\": 32,  \"conv2_filters\": 64,  \"fc1_size\": 128},\n",
    "    {\"id\": \"C_32_64_256\",     \"conv1_filters\": 32,  \"conv2_filters\": 64,  \"fc1_size\": 256},\n",
    "    {\"id\": \"C_64_128_128\",    \"conv1_filters\": 64,  \"conv2_filters\": 128, \"fc1_size\": 128},\n",
    "    {\"id\": \"C_64_128_256\",    \"conv1_filters\": 64,  \"conv2_filters\": 128, \"fc1_size\": 256},\n",
    "    {\"id\": \"C_64_128_512\",    \"conv1_filters\": 64,  \"conv2_filters\": 128, \"fc1_size\": 512},\n",
    "    {\"id\": \"C_128_256_512\",   \"conv1_filters\": 128, \"conv2_filters\": 256, \"fc1_size\": 512},\n",
    "    {\"id\": \"C_128_256_1024\",  \"conv1_filters\": 128, \"conv2_filters\": 256, \"fc1_size\": 1024},\n",
    "    {\"id\": \"C_256_512_1024\",  \"conv1_filters\": 256, \"conv2_filters\": 512, \"fc1_size\": 1024},\n",
    "    {\"id\": \"C_512_1024_1024\", \"conv1_filters\": 512, \"conv2_filters\": 1024,\"fc1_size\": 1024},\n",
    "]\n",
    "\n",
    "# ----------------------------------\n",
    "# 6. Main driver for Set C\n",
    "# ----------------------------------\n",
    "\n",
    "def run_set_c_experiment(\n",
    "    epochs: int = EPOCHS_C,\n",
    "    batch_size: int = BATCH_SIZE_C,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Runs the full Model Set C experiment on Fashion-MNIST and computes\n",
    "    GSCM along with baseline complexity measures.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Set C: Fashion-MNIST CNN Ensemble (GSCM Core) ---\")\n",
    "    print(f\"Architectures: {len(ARCHITECTURE_CONFIGS)}, Epochs: {epochs}, Device: {DEVICE}\")\n",
    "\n",
    "    train_loader, test_loader = load_fashion_mnist(batch_size=batch_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    all_results: list[dict] = []\n",
    "\n",
    "    for config in tqdm(ARCHITECTURE_CONFIGS, desc=\"Training Set C models\"):\n",
    "        try:\n",
    "            metrics = train_and_evaluate_cnn(\n",
    "                config=config,\n",
    "                train_loader=train_loader,\n",
    "                test_loader=test_loader,\n",
    "                epochs=epochs,\n",
    "                lr=LR_C,\n",
    "                device=DEVICE,\n",
    "            )\n",
    "            all_results.append(metrics)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {config['id']}: {e}\")\n",
    "            continue\n",
    "\n",
    "    df_c = pd.DataFrame(all_results)\n",
    "\n",
    "    # Empirical max normalisation for GSCM components\n",
    "    S_max = df_c[\"sharpness\"].max()\n",
    "    N_max = df_c[\"l2_norm\"].max()\n",
    "\n",
    "    df_c[\"s_norm\"] = df_c[\"sharpness\"] / S_max\n",
    "    df_c[\"n_norm\"] = df_c[\"l2_norm\"] / N_max\n",
    "    df_c[\"gscm_score\"] = 0.5 * df_c[\"s_norm\"] + 0.5 * df_c[\"n_norm\"]\n",
    "\n",
    "    out_name = \"dissertation_results_set_c.csv\"\n",
    "    df_c.to_csv(out_name, index=False)\n",
    "\n",
    "    print(\"\\nSet C summary (sorted by parameter count):\")\n",
    "    print(\n",
    "        df_c[\n",
    "            [\"id\", \"params\", \"train_error\", \"test_error\", \"gen_gap\", \"gscm_score\"]\n",
    "        ].sort_values(\"params\")\n",
    "    )\n",
    "    print(f\"\\nSet C results saved to '{out_name}'\")\n",
    "\n",
    "    return df_c\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_set_c_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb10f9-5d6e-462f-af64-92746ec913a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
